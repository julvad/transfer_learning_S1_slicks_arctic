{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# This should print the project folder\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_folder = <path to user folder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Available'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arcpy  \n",
    "from arcpy.ia import * \n",
    "arcpy.CheckExtension(\"ImageAnalyst\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Available'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "arcpy.CheckExtension('Spatial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = os.getcwd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename training/test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by assigning a number to each training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]\n",
    "\n",
    "for ts in tile_sizes:\n",
    "    for ps in pixel_sizes:\n",
    "        # Path to training samples folder\n",
    "        ts_folder = f'data/training_samples/ts_{ts}_{ps}/ts_svalbard'\n",
    "\n",
    "        # List all the folders in the ts folder\n",
    "        folders = [f for f in os.listdir(ts_folder) if os.path.isdir(os.path.join(ts_folder, f))]\n",
    "\n",
    "        # Rename each folder \n",
    "        for int, folder in enumerate(folders, start=1):\n",
    "            old_folder_path = os.path.join(ts_folder, folder)\n",
    "            new_folder_name = f\"sample_{int}\"\n",
    "            new_folder_path = os.path.join(ts_folder, new_folder_name)\n",
    "            \n",
    "            # Rename the folder\n",
    "            os.rename(old_folder_path, new_folder_path)\n",
    "            print(f\"Renamed '{folder}' to '{new_folder_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random test/train splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svalbard model has 100 samples. We first generate a random list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 146, 17, 66, 31, 127, 116, 121, 98, 54, 25, 125, 8, 100, 111, 1, 115, 69, 59, 27, 82, 157, 6, 7, 3, 150, 56, 109, 137, 57, 113, 151, 64, 71, 30, 45, 124, 87, 29, 133, 140, 38, 134, 149, 108, 72, 83, 13, 24, 81, 93, 117, 16, 96, 43, 114, 92, 65, 55, 101, 86, 148, 39, 37, 76, 126, 99, 51, 94, 5, 62, 32, 52, 142, 23, 47, 147, 48, 12, 129, 155, 14, 21, 67, 91, 131, 63, 4, 61, 136, 40, 74, 22, 78, 122, 128, 143, 50, 144, 158, 132, 36, 15, 26, 33, 84, 95, 53, 103, 18, 104, 79, 105, 88, 97, 85, 9, 34, 112, 77, 28, 138, 154, 110, 60, 73, 139, 106, 153, 80, 46, 120, 123, 49, 44, 20, 75, 11, 58, 145, 130, 141, 156, 107, 2, 41, 42, 89, 19, 102, 70, 135, 10, 119, 68, 118, 90, 152]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Seed for reproductibility\n",
    "random.seed(1)\n",
    "\n",
    "# Generate a random list of the numbers between 1 and 158\n",
    "indices = random.sample(range(1, 159), 158)\n",
    "\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set aside 15 set out of 95 for testing purposes. This will remain untouched until the final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['/data/training_samples/ts_256_25/ts_svalbard/sample_153', '/data/training_samples/ts_256_25/ts_svalbard/sample_80', '/data/training_samples/ts_256_25/ts_svalbard/sample_46', '/data/training_samples/ts_256_25/ts_svalbard/sample_120', '/data/training_samples/ts_256_25/ts_svalbard/sample_123', '/data/training_samples/ts_256_25/ts_svalbard/sample_49', '/data/training_samples/ts_256_25/ts_svalbard/sample_44', '/data/training_samples/ts_256_25/ts_svalbard/sample_20', '/data/training_samples/ts_256_25/ts_svalbard/sample_75', '/data/training_samples/ts_256_25/ts_svalbard/sample_11', '/data/training_samples/ts_256_25/ts_svalbard/sample_58', '/data/training_samples/ts_256_25/ts_svalbard/sample_145', '/data/training_samples/ts_256_25/ts_svalbard/sample_130', '/data/training_samples/ts_256_25/ts_svalbard/sample_141', '/data/training_samples/ts_256_25/ts_svalbard/sample_156', '/data/training_samples/ts_256_25/ts_svalbard/sample_107', '/data/training_samples/ts_256_25/ts_svalbard/sample_2', '/data/training_samples/ts_256_25/ts_svalbard/sample_41', '/data/training_samples/ts_256_25/ts_svalbard/sample_42', '/data/training_samples/ts_256_25/ts_svalbard/sample_89', '/data/training_samples/ts_256_25/ts_svalbard/sample_19', '/data/training_samples/ts_256_25/ts_svalbard/sample_102', '/data/training_samples/ts_256_25/ts_svalbard/sample_70', '/data/training_samples/ts_256_25/ts_svalbard/sample_135', '/data/training_samples/ts_256_25/ts_svalbard/sample_10', '/data/training_samples/ts_256_25/ts_svalbard/sample_119', '/data/training_samples/ts_256_25/ts_svalbard/sample_68', '/data/training_samples/ts_256_25/ts_svalbard/sample_118', '/data/training_samples/ts_256_25/ts_svalbard/sample_90', '/data/training_samples/ts_256_25/ts_svalbard/sample_152']\n"
     ]
    }
   ],
   "source": [
    "test_split = []\n",
    "\n",
    "for i in indices[128:]:\n",
    "    test_split.append(f'/data/training_samples/ts_256_25/ts_svalbard/sample_{i}')\n",
    "\n",
    "print(len(test_split))\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "['/data/training_samples/ts_256_25/ts_svalbard/sample_35', '/data/training_samples/ts_256_25/ts_svalbard/sample_146', '/data/training_samples/ts_256_25/ts_svalbard/sample_17', '/data/training_samples/ts_256_25/ts_svalbard/sample_66', '/data/training_samples/ts_256_25/ts_svalbard/sample_31', '/data/training_samples/ts_256_25/ts_svalbard/sample_127', '/data/training_samples/ts_256_25/ts_svalbard/sample_116', '/data/training_samples/ts_256_25/ts_svalbard/sample_121', '/data/training_samples/ts_256_25/ts_svalbard/sample_98', '/data/training_samples/ts_256_25/ts_svalbard/sample_54', '/data/training_samples/ts_256_25/ts_svalbard/sample_25', '/data/training_samples/ts_256_25/ts_svalbard/sample_125', '/data/training_samples/ts_256_25/ts_svalbard/sample_8', '/data/training_samples/ts_256_25/ts_svalbard/sample_100', '/data/training_samples/ts_256_25/ts_svalbard/sample_111', '/data/training_samples/ts_256_25/ts_svalbard/sample_1', '/data/training_samples/ts_256_25/ts_svalbard/sample_115', '/data/training_samples/ts_256_25/ts_svalbard/sample_69', '/data/training_samples/ts_256_25/ts_svalbard/sample_59', '/data/training_samples/ts_256_25/ts_svalbard/sample_27', '/data/training_samples/ts_256_25/ts_svalbard/sample_82', '/data/training_samples/ts_256_25/ts_svalbard/sample_157', '/data/training_samples/ts_256_25/ts_svalbard/sample_6', '/data/training_samples/ts_256_25/ts_svalbard/sample_7', '/data/training_samples/ts_256_25/ts_svalbard/sample_3', '/data/training_samples/ts_256_25/ts_svalbard/sample_150', '/data/training_samples/ts_256_25/ts_svalbard/sample_56', '/data/training_samples/ts_256_25/ts_svalbard/sample_109', '/data/training_samples/ts_256_25/ts_svalbard/sample_137', '/data/training_samples/ts_256_25/ts_svalbard/sample_57', '/data/training_samples/ts_256_25/ts_svalbard/sample_113', '/data/training_samples/ts_256_25/ts_svalbard/sample_151', '/data/training_samples/ts_256_25/ts_svalbard/sample_64', '/data/training_samples/ts_256_25/ts_svalbard/sample_71', '/data/training_samples/ts_256_25/ts_svalbard/sample_30', '/data/training_samples/ts_256_25/ts_svalbard/sample_45', '/data/training_samples/ts_256_25/ts_svalbard/sample_124', '/data/training_samples/ts_256_25/ts_svalbard/sample_87', '/data/training_samples/ts_256_25/ts_svalbard/sample_29', '/data/training_samples/ts_256_25/ts_svalbard/sample_133', '/data/training_samples/ts_256_25/ts_svalbard/sample_140', '/data/training_samples/ts_256_25/ts_svalbard/sample_38', '/data/training_samples/ts_256_25/ts_svalbard/sample_134', '/data/training_samples/ts_256_25/ts_svalbard/sample_149', '/data/training_samples/ts_256_25/ts_svalbard/sample_108', '/data/training_samples/ts_256_25/ts_svalbard/sample_72', '/data/training_samples/ts_256_25/ts_svalbard/sample_83', '/data/training_samples/ts_256_25/ts_svalbard/sample_13', '/data/training_samples/ts_256_25/ts_svalbard/sample_24', '/data/training_samples/ts_256_25/ts_svalbard/sample_81', '/data/training_samples/ts_256_25/ts_svalbard/sample_93', '/data/training_samples/ts_256_25/ts_svalbard/sample_117', '/data/training_samples/ts_256_25/ts_svalbard/sample_16', '/data/training_samples/ts_256_25/ts_svalbard/sample_96', '/data/training_samples/ts_256_25/ts_svalbard/sample_43', '/data/training_samples/ts_256_25/ts_svalbard/sample_114', '/data/training_samples/ts_256_25/ts_svalbard/sample_92', '/data/training_samples/ts_256_25/ts_svalbard/sample_65', '/data/training_samples/ts_256_25/ts_svalbard/sample_55', '/data/training_samples/ts_256_25/ts_svalbard/sample_101', '/data/training_samples/ts_256_25/ts_svalbard/sample_86', '/data/training_samples/ts_256_25/ts_svalbard/sample_148', '/data/training_samples/ts_256_25/ts_svalbard/sample_39', '/data/training_samples/ts_256_25/ts_svalbard/sample_37', '/data/training_samples/ts_256_25/ts_svalbard/sample_76', '/data/training_samples/ts_256_25/ts_svalbard/sample_126', '/data/training_samples/ts_256_25/ts_svalbard/sample_99', '/data/training_samples/ts_256_25/ts_svalbard/sample_51', '/data/training_samples/ts_256_25/ts_svalbard/sample_94', '/data/training_samples/ts_256_25/ts_svalbard/sample_5', '/data/training_samples/ts_256_25/ts_svalbard/sample_62', '/data/training_samples/ts_256_25/ts_svalbard/sample_32', '/data/training_samples/ts_256_25/ts_svalbard/sample_52', '/data/training_samples/ts_256_25/ts_svalbard/sample_142', '/data/training_samples/ts_256_25/ts_svalbard/sample_23', '/data/training_samples/ts_256_25/ts_svalbard/sample_47', '/data/training_samples/ts_256_25/ts_svalbard/sample_147', '/data/training_samples/ts_256_25/ts_svalbard/sample_48', '/data/training_samples/ts_256_25/ts_svalbard/sample_12', '/data/training_samples/ts_256_25/ts_svalbard/sample_129', '/data/training_samples/ts_256_25/ts_svalbard/sample_155', '/data/training_samples/ts_256_25/ts_svalbard/sample_14', '/data/training_samples/ts_256_25/ts_svalbard/sample_21', '/data/training_samples/ts_256_25/ts_svalbard/sample_67', '/data/training_samples/ts_256_25/ts_svalbard/sample_91', '/data/training_samples/ts_256_25/ts_svalbard/sample_131', '/data/training_samples/ts_256_25/ts_svalbard/sample_63', '/data/training_samples/ts_256_25/ts_svalbard/sample_4', '/data/training_samples/ts_256_25/ts_svalbard/sample_61', '/data/training_samples/ts_256_25/ts_svalbard/sample_136', '/data/training_samples/ts_256_25/ts_svalbard/sample_40', '/data/training_samples/ts_256_25/ts_svalbard/sample_74', '/data/training_samples/ts_256_25/ts_svalbard/sample_22', '/data/training_samples/ts_256_25/ts_svalbard/sample_78', '/data/training_samples/ts_256_25/ts_svalbard/sample_122', '/data/training_samples/ts_256_25/ts_svalbard/sample_128', '/data/training_samples/ts_256_25/ts_svalbard/sample_143', '/data/training_samples/ts_256_25/ts_svalbard/sample_50', '/data/training_samples/ts_256_25/ts_svalbard/sample_144', '/data/training_samples/ts_256_25/ts_svalbard/sample_158', '/data/training_samples/ts_256_25/ts_svalbard/sample_132', '/data/training_samples/ts_256_25/ts_svalbard/sample_36', '/data/training_samples/ts_256_25/ts_svalbard/sample_15', '/data/training_samples/ts_256_25/ts_svalbard/sample_26', '/data/training_samples/ts_256_25/ts_svalbard/sample_33', '/data/training_samples/ts_256_25/ts_svalbard/sample_84', '/data/training_samples/ts_256_25/ts_svalbard/sample_95', '/data/training_samples/ts_256_25/ts_svalbard/sample_53', '/data/training_samples/ts_256_25/ts_svalbard/sample_103', '/data/training_samples/ts_256_25/ts_svalbard/sample_18', '/data/training_samples/ts_256_25/ts_svalbard/sample_104', '/data/training_samples/ts_256_25/ts_svalbard/sample_79', '/data/training_samples/ts_256_25/ts_svalbard/sample_105', '/data/training_samples/ts_256_25/ts_svalbard/sample_88', '/data/training_samples/ts_256_25/ts_svalbard/sample_97', '/data/training_samples/ts_256_25/ts_svalbard/sample_85', '/data/training_samples/ts_256_25/ts_svalbard/sample_9', '/data/training_samples/ts_256_25/ts_svalbard/sample_34', '/data/training_samples/ts_256_25/ts_svalbard/sample_112', '/data/training_samples/ts_256_25/ts_svalbard/sample_77', '/data/training_samples/ts_256_25/ts_svalbard/sample_28', '/data/training_samples/ts_256_25/ts_svalbard/sample_138', '/data/training_samples/ts_256_25/ts_svalbard/sample_154', '/data/training_samples/ts_256_25/ts_svalbard/sample_110', '/data/training_samples/ts_256_25/ts_svalbard/sample_60', '/data/training_samples/ts_256_25/ts_svalbard/sample_73', '/data/training_samples/ts_256_25/ts_svalbard/sample_139', '/data/training_samples/ts_256_25/ts_svalbard/sample_106']\n"
     ]
    }
   ],
   "source": [
    "train_split = []\n",
    "\n",
    "for i in indices[:128]:\n",
    "    train_split.append(f'/data/training_samples/ts_256_25/ts_svalbard/sample_{i}')\n",
    "\n",
    "print(len(train_split))\n",
    "print(train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = os.getcwd()\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      17.00% [17/100 7:32:54<36:51:13]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.517236</td>\n",
       "      <td>0.308145</td>\n",
       "      <td>0.996732</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.500766</td>\n",
       "      <td>0.271038</td>\n",
       "      <td>0.997015</td>\n",
       "      <td>0.676395</td>\n",
       "      <td>25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.513386</td>\n",
       "      <td>0.256521</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>0.692954</td>\n",
       "      <td>25:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501986</td>\n",
       "      <td>0.251423</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>0.698160</td>\n",
       "      <td>25:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.503335</td>\n",
       "      <td>0.255145</td>\n",
       "      <td>0.997185</td>\n",
       "      <td>0.694378</td>\n",
       "      <td>25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.478140</td>\n",
       "      <td>0.234944</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.715768</td>\n",
       "      <td>25:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.506126</td>\n",
       "      <td>0.251309</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.694808</td>\n",
       "      <td>25:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.239064</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>0.710893</td>\n",
       "      <td>25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.478991</td>\n",
       "      <td>0.238973</td>\n",
       "      <td>0.997163</td>\n",
       "      <td>0.709628</td>\n",
       "      <td>25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>0.231742</td>\n",
       "      <td>0.997377</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>25:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.506791</td>\n",
       "      <td>0.242590</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.707030</td>\n",
       "      <td>25:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.486896</td>\n",
       "      <td>0.227621</td>\n",
       "      <td>0.997350</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.478041</td>\n",
       "      <td>0.247364</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.700046</td>\n",
       "      <td>29:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.509094</td>\n",
       "      <td>0.246445</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.701359</td>\n",
       "      <td>29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.497333</td>\n",
       "      <td>0.226984</td>\n",
       "      <td>0.997080</td>\n",
       "      <td>0.724713</td>\n",
       "      <td>29:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.502377</td>\n",
       "      <td>0.237272</td>\n",
       "      <td>0.997109</td>\n",
       "      <td>0.711452</td>\n",
       "      <td>29:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.484431</td>\n",
       "      <td>0.246662</td>\n",
       "      <td>0.997146</td>\n",
       "      <td>0.699490</td>\n",
       "      <td>29:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131' class='' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131/131 00:59<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "Computing model metrics...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]\n",
    "\n",
    "backbones = ['VIT_B','VIT_L']\n",
    "\n",
    "for tilesize in tile_sizes:\n",
    "    for pixelsize in pixel_sizes:\n",
    "        # create train folder list\n",
    "        train_list = []\n",
    "\n",
    "        root = f\"data/training_samples/ts_{tilesize}_{pixelsize}/ts_ns2019\"\n",
    "        for folder in os.listdir(root):\n",
    "            folder_path = '/' + os.path.join(root,folder)\n",
    "            train_list.append(folder_path)\n",
    "            \n",
    "        root = f\"data/training_samples/ts_{tilesize}_{pixelsize}/ts_rune\"\n",
    "        for folder in os.listdir(root):\n",
    "            folder_path = '/' + os.path.join(root,folder)\n",
    "            train_list.append(folder_path)\n",
    "        \n",
    "        # shuffle to avoid validation bias\n",
    "        random.shuffle(train_list)\n",
    "\n",
    "        for backbone in backbones:\n",
    "            if tilesize == 256:\n",
    "                bs = 64\n",
    "            if tilesize == 512:\n",
    "                bs = 16\n",
    "            if backbone == 'VIT_L':\n",
    "                bs = bs / 4\n",
    "\n",
    "            print(f'training for {tilesize}m x {pixelsize}m for {backbone} and batchsize = {bs}')\n",
    "            with arcpy.EnvManager(processorType=\"GPU\"):\n",
    "                TrainDeepLearningModel(\n",
    "                    in_folder = train_list,\n",
    "                    out_folder = f'/models/pretrained/samlora_{tilesize}_{pixelsize}_{backbone}', \n",
    "                    max_epochs=100,\n",
    "                    model_type=\"SAMLORA\",\n",
    "                    batch_size=bs,\n",
    "                    arguments=f\"class_balancing True;mixup False;focal_loss False;ignore_classes #;dice_loss_fraction 0.5\",\n",
    "                    learning_rate=None,\n",
    "                    backbone_model=backbone,\n",
    "                    validation_percentage=10,\n",
    "                    stop_training=\"STOP_TRAINING\",\n",
    "                    freeze=\"UNFREEZE_MODEL\",\n",
    "                    augmentation=\"DEFAULT\",\n",
    "                    augmentation_parameters=None,\n",
    "                    chip_size = tilesize,\n",
    "                    resize_to=\"\",\n",
    "                    weight_init_scheme=\"\",\n",
    "                    monitor=\"VALID_LOSS\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEPLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: early stopping\n",
      "Computing model metrics...\n"
     ]
    }
   ],
   "source": [
    "tile_sizes = [512]\n",
    "pixel_sizes = [25]\n",
    "\n",
    "backbones = ['RESNET50','RESNET101']\n",
    "\n",
    "for tilesize in tile_sizes:\n",
    "    for pixelsize in pixel_sizes:\n",
    "        # create train folder list\n",
    "        train_list = []\n",
    "\n",
    "        root = f\"data/training_samples/ts_{tilesize}_{pixelsize}/ts_ns2019\"\n",
    "        for folder in os.listdir(root):\n",
    "            folder_path = '/' + os.path.join(root,folder)\n",
    "            train_list.append(folder_path)\n",
    "            \n",
    "        root = f\"data/training_samples/ts_{tilesize}_{pixelsize}/ts_rune\"\n",
    "        for folder in os.listdir(root):\n",
    "            folder_path = '/' + os.path.join(root,folder)\n",
    "            train_list.append(folder_path)\n",
    "\n",
    "        random.shuffle(train_list)\n",
    "\n",
    "        for backbone in backbones: \n",
    "            if tilesize == 256:\n",
    "                bs = 64\n",
    "            if tilesize == 512:\n",
    "                bs = 16\n",
    "            if backbone == 'RESNET101':\n",
    "                bs =  bs / 2\n",
    "            print(f'training for {tilesize}m x {pixelsize}m for {backbone} and batchsize = {bs}')\n",
    "            with arcpy.EnvManager(processorType=\"GPU\"):\n",
    "                arcpy.ia.TrainDeepLearningModel(\n",
    "                    in_folder = train_list,\n",
    "                    out_folder = f\"/models/pretrained/deeplab_{tilesize}_{pixelsize}_{backbone}\",  \n",
    "                    max_epochs=100,\n",
    "                    model_type=\"DEEPLAB\", \n",
    "                    arguments=f\"class_balancing True;mixup False;focal_loss False;ignore_classes #;dice_loss_fraction 0.5\",\n",
    "                    batch_size=bs,\n",
    "                    learning_rate=None,\n",
    "                    backbone_model=backbone,\n",
    "                    validation_percentage=10,\n",
    "                    stop_training=\"STOP_TRAINING\",\n",
    "                    freeze=\"UNFREEZE_MODEL\",\n",
    "                    augmentation=\"DEFAULT\",\n",
    "                    augmentation_parameters=None,\n",
    "                    chip_size=tilesize,\n",
    "                    monitor=\"VALID_LOSS\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate random hyperparameters. as recommended by Goodfellow et al 2015 and Djikstra & Bengio 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random search\n",
    "# random.seed(1)\n",
    "\n",
    "# # Define search space for each hyperparameter\n",
    "# backbones = ['RESNET50', 'RESNET101']\n",
    "# # bsizes = [4, 8, 12, 16, 22]\n",
    "# # lrates = [1e-5, 1e-4, 1e-3]\n",
    "\n",
    "# # Number of random combinations to test \n",
    "# num_combinations = 8\n",
    "\n",
    "# # Create a set to track unique combinations\n",
    "# unique_combinations = set()\n",
    "\n",
    "# # Randomly sample combinations ensuring no duplicates\n",
    "# while len(unique_combinations) < num_combinations:\n",
    "#     backbone = random.choice(backbones)\n",
    "#     batch_size = random.choice(bsizes)\n",
    "#     learning_rate = random.choice(lrates)\n",
    "    \n",
    "#     # Use a tuple to store the combination as a hashable element in the set\n",
    "#     combination = (backbone, batch_size, learning_rate)\n",
    "    \n",
    "#     # Add the combination to the set (duplicates will be ignored)\n",
    "#     unique_combinations.add(combination)\n",
    "\n",
    "# # Convert the set of combinations back into a list for further processing\n",
    "# random_combinations = [{'backbone': b, 'batch_size': s, 'learning_rate': lr} for b, s, lr in unique_combinations]\n",
    "\n",
    "# # Print the random combinations\n",
    "# for i, config in enumerate(random_combinations):\n",
    "#     print(f\"Random search config {i+1}: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base models batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.ResetEnvironments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]\n",
    "\n",
    "N_train_sets = [2,8,32,128] # N = 4\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of model per tilesize-pixelsize-backbone combination\n",
    "    # if N = 7: \n",
    "        # if b = 1: 8 models per N. 8*7 = 56 models for deeplab. 112 base models. With transfer learning = Total of 224 models\n",
    "        # if b = 2: 16 models per N. 16*7 = 112 models for Deeplab. 224 base models. With transfer learning = Total of 448 models\n",
    "\n",
    "    # if N = 4: \n",
    "        # if b = 1: 8 models per N. 8*4 = 32 models for deeplab. 64 base models. With transfer learning = Total of 128 models\n",
    "        # if b = 2: 16 models per N. 16*4 = 64 models for Deeplab. 128 base models. With transfer learning = Total of 256 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      17.00% [17/100 21:36<1:45:27]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.626564</td>\n",
       "      <td>0.535755</td>\n",
       "      <td>0.970991</td>\n",
       "      <td>0.312233</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.516920</td>\n",
       "      <td>0.402992</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>0.511662</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.361409</td>\n",
       "      <td>0.985277</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.412021</td>\n",
       "      <td>0.290429</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.543668</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.386397</td>\n",
       "      <td>0.252109</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>0.587188</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.364923</td>\n",
       "      <td>0.255169</td>\n",
       "      <td>0.988469</td>\n",
       "      <td>0.555338</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.363651</td>\n",
       "      <td>0.289812</td>\n",
       "      <td>0.988038</td>\n",
       "      <td>0.508385</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.364088</td>\n",
       "      <td>0.227577</td>\n",
       "      <td>0.992402</td>\n",
       "      <td>0.595130</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.360778</td>\n",
       "      <td>0.282222</td>\n",
       "      <td>0.988796</td>\n",
       "      <td>0.496962</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.250150</td>\n",
       "      <td>0.986843</td>\n",
       "      <td>0.564794</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.358882</td>\n",
       "      <td>0.253729</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>0.552729</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.360263</td>\n",
       "      <td>0.219766</td>\n",
       "      <td>0.992082</td>\n",
       "      <td>0.622140</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.355252</td>\n",
       "      <td>0.252513</td>\n",
       "      <td>0.990437</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361840</td>\n",
       "      <td>0.267807</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.528978</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.355232</td>\n",
       "      <td>0.240241</td>\n",
       "      <td>0.991944</td>\n",
       "      <td>0.586674</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.366174</td>\n",
       "      <td>0.244481</td>\n",
       "      <td>0.990921</td>\n",
       "      <td>0.570728</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>0.234708</td>\n",
       "      <td>0.990793</td>\n",
       "      <td>0.586527</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [9/9 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "Computing model metrics...\n"
     ]
    }
   ],
   "source": [
    "# make sure the workspace refers to the project folder\n",
    "arcpy.env.workspace = os.getcwd()\n",
    "\n",
    "# arcpy.env.processorType = 'GPU'\n",
    "\n",
    "backbones = ['RESNET50', 'RESNET101']\n",
    "\n",
    "for tilesize in tile_sizes:\n",
    "    for pixelsize in pixel_sizes:\n",
    "        # Load train split for tile format\n",
    "        train_split = []\n",
    "        for i in indices[:128]:\n",
    "            train_split.append(f'/data/training_samples/ts_{tilesize}_{pixelsize}/ts_svalbard/sample_{i}')\n",
    "\n",
    "        for N in N_train_sets: # for N in the set of training samples\n",
    "            # Adaptive batchsize based on GPU memory\n",
    "            for backbone in backbones:\n",
    "                if backbone == 'RESNET50':\n",
    "                    if tilesize == 256:\n",
    "                        bs = 64\n",
    "                    else: # if ts = 512\n",
    "                        bs = 16\n",
    "                else:\n",
    "                    if tilesize == 256:\n",
    "                        bs = 32\n",
    "                    else: # if ts = 512\n",
    "                        bs = 8\n",
    "            \n",
    "                if N <= 8:\n",
    "                    bs = N\n",
    "                \n",
    "                for s in range(b): # for b, the number of bootstraps\n",
    "                    if N <= 8:\n",
    "                        N += 1 # 10% val fix for small numbers\n",
    "\n",
    "                    # load N bootstrapped images from train split\n",
    "                    train_in = random.sample(train_split,N)\n",
    "\n",
    "                    if N <= 9:\n",
    "                        N -= 1 #return N to initial value\n",
    "                \n",
    "                    out_path = f'/models/base/deeplab_{tilesize}_{pixelsize}_n{N}_{backbone}'\n",
    "                    if not os.path.isdir(out_path.removeprefix('/')):\n",
    "                        # train model\n",
    "                        print(f'training model for ts {tilesize}, ps {pixelsize}, backbone {backbone}, with {N} images and batch size {bs}')\n",
    "                        # print(f'input training data: {train_in}')\n",
    "                        with arcpy.EnvManager(processorType=\"GPU\"):\n",
    "                            TrainDeepLearningModel(\n",
    "                                in_folder = train_in,\n",
    "                                out_folder = out_path,\n",
    "                                max_epochs=100,\n",
    "                                model_type=\"DEEPLAB\",\n",
    "                                batch_size=bs,\n",
    "                                arguments=\"class_balancing True;mixup False;focal_loss False;ignore_classes #;dice_loss_fraction 0.5\", # weighted combo loss function\n",
    "                                learning_rate=None, # automatic optimization from an estimated learning curve\n",
    "                                backbone_model=backbone,\n",
    "                                pretrained_model=None,\n",
    "                                validation_percentage=10,\n",
    "                                stop_training=\"STOP_TRAINING\",\n",
    "                                freeze=\"UNFREEZE_MODEL\",\n",
    "                                augmentation=\"DEFAULT\",\n",
    "                                augmentation_parameters=None,\n",
    "                                chip_size=tilesize,\n",
    "                                resize_to=\"\",\n",
    "                                weight_init_scheme=\"\", \n",
    "                                monitor=\"VALID_LOSS\"\n",
    "                            )\n",
    "                    else:\n",
    "                        print(f'{out_path} already exists, skipping')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='16' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.00% [16/100 55:06<4:49:16]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.562685</td>\n",
       "      <td>0.289270</td>\n",
       "      <td>0.992082</td>\n",
       "      <td>0.661609</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.520248</td>\n",
       "      <td>0.264214</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>0.691240</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.492761</td>\n",
       "      <td>0.232817</td>\n",
       "      <td>0.992999</td>\n",
       "      <td>0.731147</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466531</td>\n",
       "      <td>0.243246</td>\n",
       "      <td>0.994088</td>\n",
       "      <td>0.712817</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.484075</td>\n",
       "      <td>0.228792</td>\n",
       "      <td>0.993948</td>\n",
       "      <td>0.733622</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.484205</td>\n",
       "      <td>0.234356</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.725506</td>\n",
       "      <td>03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.470976</td>\n",
       "      <td>0.235827</td>\n",
       "      <td>0.993149</td>\n",
       "      <td>0.720656</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.481245</td>\n",
       "      <td>0.225926</td>\n",
       "      <td>0.993603</td>\n",
       "      <td>0.732241</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.485167</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.991693</td>\n",
       "      <td>0.694133</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.483335</td>\n",
       "      <td>0.261862</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.689228</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.452949</td>\n",
       "      <td>0.223523</td>\n",
       "      <td>0.993804</td>\n",
       "      <td>0.733445</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.487256</td>\n",
       "      <td>0.238438</td>\n",
       "      <td>0.992583</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.484335</td>\n",
       "      <td>0.254497</td>\n",
       "      <td>0.993259</td>\n",
       "      <td>0.699058</td>\n",
       "      <td>03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.458653</td>\n",
       "      <td>0.255442</td>\n",
       "      <td>0.991733</td>\n",
       "      <td>0.697878</td>\n",
       "      <td>03:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.480713</td>\n",
       "      <td>0.248047</td>\n",
       "      <td>0.993755</td>\n",
       "      <td>0.704984</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>0.241245</td>\n",
       "      <td>0.993215</td>\n",
       "      <td>0.713403</td>\n",
       "      <td>03:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [17/17 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "Computing model metrics...\n"
     ]
    }
   ],
   "source": [
    "# make sure the workspace refers to the project folder\n",
    "arcpy.env.workspace = os.getcwd()\n",
    "\n",
    "# arcpy.env.processorType = 'GPU'\n",
    "\n",
    "backbones = ['VIT_B','VIT_L']\n",
    "\n",
    "for tilesize in tile_sizes:\n",
    "    for pixelsize in pixel_sizes:\n",
    "        # Load train split for tile format\n",
    "        train_split = []\n",
    "        for i in indices[:128]:\n",
    "            train_split.append(f'/data/training_samples/ts_{tilesize}_{pixelsize}/ts_svalbard/sample_{i}')\n",
    "        for N in N_train_sets: # for N in the set of training samples\n",
    "            # Adaptive batchsize based on GPU memory\n",
    "            for backbone in backbones:\n",
    "                if tilesize == 256:\n",
    "                    if backbone == 'VIT_B':\n",
    "                        bs = 64\n",
    "                    else: # if bb = Vit-L\n",
    "                        bs = 16\n",
    "                else: # if ts = 512\n",
    "                    if backbone == 'VIT_B':\n",
    "                        bs = 16\n",
    "                    else: # bb = Vit-L\n",
    "                        bs = 4\n",
    "            \n",
    "                if (N <= 8) and (bs != 4):\n",
    "                    bs = N\n",
    "\n",
    "                for s in range(b): # for b, the number of bootstraps\n",
    "                    if N <= 8:\n",
    "                        N += 1 # 10% val fix for small numbers\n",
    "\n",
    "                    # load N bootstrapped images from train split\n",
    "                    train_in = random.sample(train_split,N)\n",
    "\n",
    "                    if N <= 9:\n",
    "                        N -= 1 #return N to initial value\n",
    "\n",
    "                    out_path = f'/models/base/samlora_{tilesize}_{pixelsize}_n{N}_{backbone}'\n",
    "                    if not os.path.isdir(out_path.removeprefix('/')):\n",
    "                        # train model\n",
    "                        print(f'training for ts {tilesize}, ps {pixelsize}, backbone {backbone}, with {N} images and batch size {bs}...')\n",
    "                        # print(f'input training data: {train_in}')\n",
    "                        with arcpy.EnvManager(processorType=\"GPU\"):\n",
    "                            TrainDeepLearningModel(\n",
    "                                in_folder = train_in,\n",
    "                                out_folder = out_path,\n",
    "                                max_epochs=100,\n",
    "                                model_type=\"SAMLORA\",\n",
    "                                batch_size=bs,\n",
    "                                arguments=\"class_balancing True;mixup False;focal_loss False;ignore_classes #;dice_loss_fraction 0.5\", # weighted combo loss function\n",
    "                                learning_rate=None, # automatic optimization from an estimated learning curve\n",
    "                                backbone_model=backbone,\n",
    "                                pretrained_model=None,\n",
    "                                # pretrained_model= None,\n",
    "                                validation_percentage=10,\n",
    "                                stop_training=\"STOP_TRAINING\",\n",
    "                                freeze=\"UNFREEZE_MODEL\",\n",
    "                                augmentation=\"DEFAULT\",\n",
    "                                augmentation_parameters=None,\n",
    "                                chip_size=tilesize,\n",
    "                                resize_to=\"\",\n",
    "                                weight_init_scheme=\"\", \n",
    "                                monitor=\"VALID_LOSS\"\n",
    "                            )\n",
    "                    else: \n",
    "                        print(f'{out_path} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL models batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.ResetEnvironments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of model per tilesize-pixelsize-backbone combination\n",
    "    # if N = 7: \n",
    "        # if b = 1: 8 models per N. 8*7 = 56 models for deeplab. 112 base models. With transfer learning = Total of 224 models\n",
    "        # if b = 2: 16 models per N. 16*7 = 112 models for Deeplab. 224 base models. With transfer learning = Total of 448 models\n",
    "\n",
    "    # if N = 4: \n",
    "        # if b = 1: 8 models per N. 8*4 = 32 models for deeplab. 64 base models. With transfer learning = Total of 128 models\n",
    "        # if b = 2: 16 models per N. 16*4 = 64 models for Deeplab. 128 base models. With transfer learning = Total of 256 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]\n",
    "\n",
    "N_train_sets = [2,4,8] # N = 4\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]\n",
    "\n",
    "N_train_sets = [2,8,32,128] # N = 4\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='19' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      19.00% [19/100 01:04<04:36]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dice</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.650785</td>\n",
       "      <td>0.332560</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.591970</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.552470</td>\n",
       "      <td>0.329494</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.597549</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518776</td>\n",
       "      <td>0.326765</td>\n",
       "      <td>0.998394</td>\n",
       "      <td>0.600948</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514049</td>\n",
       "      <td>0.323361</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501969</td>\n",
       "      <td>0.319129</td>\n",
       "      <td>0.998493</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.507002</td>\n",
       "      <td>0.314168</td>\n",
       "      <td>0.998539</td>\n",
       "      <td>0.621915</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.492409</td>\n",
       "      <td>0.307926</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.626747</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.460815</td>\n",
       "      <td>0.299937</td>\n",
       "      <td>0.998665</td>\n",
       "      <td>0.642127</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.475676</td>\n",
       "      <td>0.280865</td>\n",
       "      <td>0.998817</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.480213</td>\n",
       "      <td>0.272471</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.674860</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.466514</td>\n",
       "      <td>0.265302</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.686114</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.464073</td>\n",
       "      <td>0.259790</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.690073</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.475332</td>\n",
       "      <td>0.256171</td>\n",
       "      <td>0.999088</td>\n",
       "      <td>0.697085</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.256557</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.699080</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.259283</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.683853</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.457616</td>\n",
       "      <td>0.263522</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.452899</td>\n",
       "      <td>0.268493</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.668563</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.445405</td>\n",
       "      <td>0.273507</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.663781</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "Computing model metrics...\n",
      "models/transfer_learning/samlora_512_25_n8_VIT_B already exists\n",
      "models/transfer_learning/samlora_512_25_n8_VIT_L already exists\n",
      "models/transfer_learning/samlora_512_25_n32_VIT_B already exists\n",
      "models/transfer_learning/samlora_512_25_n32_VIT_L already exists\n",
      "models/transfer_learning/samlora_512_25_n128_VIT_B already exists\n",
      "models/transfer_learning/samlora_512_25_n128_VIT_L already exists\n"
     ]
    }
   ],
   "source": [
    "# make sure the workspace refers to the project folder\n",
    "arcpy.env.workspace = os.getcwd()\n",
    "\n",
    "# arcpy.env.processorType = 'GPU'\n",
    "\n",
    "backbones = ['VIT_B','VIT_L']\n",
    "\n",
    "for tilesize in tile_sizes:\n",
    "    for pixelsize in pixel_sizes:\n",
    "        # Load train split for tile format\n",
    "        train_split = []\n",
    "        for i in indices[:128]:\n",
    "            train_split.append(f'/data/training_samples/ts_{tilesize}_{pixelsize}/ts_svalbard/sample_{i}')\n",
    "        # list of number of training samples\n",
    "        for N in N_train_sets: # for N in the set of training samples\n",
    "            # if N <= 16: \n",
    "            #     b = 2\n",
    "            # else: \n",
    "            #     b = 2\n",
    "            for backbone in backbones:\n",
    "                if backbone == 'VIT_B':\n",
    "                    if tilesize == 256:\n",
    "                        bs = 64\n",
    "                    else: # if ts = 512\n",
    "                        bs = 16\n",
    "                else: # if VIT_L\n",
    "                    if tilesize == 256:\n",
    "                        bs = 16\n",
    "                    else: # if ts = 512\n",
    "                        bs = 4\n",
    "            \n",
    "                if (N <= 8) and (bs != 4):\n",
    "                    bs = N\n",
    "\n",
    "                for s in range(b): # for b, the number of bootstraps\n",
    "                    if N <= 8:\n",
    "                        N += 1 # 10% val fix for small numbers\n",
    "\n",
    "                    # load N bootstrapped images from train split\n",
    "                    train_in = random.sample(train_split,N)\n",
    "\n",
    "                    if N <= 9:\n",
    "                        N -= 1 #return N to initial value\n",
    "\n",
    "                    out_path = f'/models/transfer_learning/samlora_{tilesize}_{pixelsize}_n{N}_{backbone}'\n",
    "                    if not os.path.isdir(out_path.removeprefix('/')):\n",
    "                    # train model\n",
    "                        print(f'training for ts {tilesize}, ps {pixelsize}, backbone {backbone}, with {N} images and batch size {bs}...')\n",
    "                        # print(f'input training data: {train_in}')\n",
    "                        with arcpy.EnvManager(processorType=\"GPU\"):\n",
    "                            TrainDeepLearningModel(\n",
    "                                in_folder = train_in,\n",
    "                                out_folder = out_path,\n",
    "                                max_epochs=100,\n",
    "                                model_type=\"SAMLORA\",\n",
    "                                batch_size=bs,\n",
    "                                arguments=\"class_balancing True;mixup False;focal_loss False;ignore_classes #;dice_loss_fraction 0.5\", # weighted combo loss function\n",
    "                                learning_rate=None, # automatic optimization from an estimated learning curve\n",
    "                                backbone_model=backbone,\n",
    "                                pretrained_model=f'/models/pretrained/samlora_{tilesize}_{pixelsize}_{backbone}/samlora_{tilesize}_{pixelsize}_{backbone}.emd',\n",
    "                                # pretrained_model= None,\n",
    "                                validation_percentage=10,\n",
    "                                stop_training=\"STOP_TRAINING\",\n",
    "                                freeze=\"UNFREEZE_MODEL\",\n",
    "                                augmentation=\"DEFAULT\",\n",
    "                                augmentation_parameters=None,\n",
    "                                chip_size=tilesize,\n",
    "                                resize_to=\"\",\n",
    "                                weight_init_scheme=\"\", \n",
    "                                monitor=\"VALID_LOSS\"\n",
    "                            )\n",
    "                    else:\n",
    "                        print(f\"{out_path.removeprefix('/')} already exists\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize training samples(0-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arcpy.env.overwriteOutput = True\n",
    "# import rasterio\n",
    "\n",
    "# # Path to the root folder containing subfolders\n",
    "# root_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_10\\ts_ns2019\"\n",
    "\n",
    "# # Iterate through the subfolders in the root folder\n",
    "# for folder in os.listdir(root_folder):\n",
    "#     folder_path = os.path.join(root_folder, folder)\n",
    "\n",
    "#     # define the images folder path\n",
    "#     images_folder_path = os.path.join(folder_path, 'images')\n",
    "#     normalized_images_path = os.makedirs(os.path.join(folder_path, 'images_norm'))\n",
    "    \n",
    "#     # iterate through all files in 'images'\n",
    "#     for file_name in os.listdir(images_folder_path):\n",
    "#         file_path = os.path.join(images_folder_path, file_name)\n",
    "\n",
    "#         # open the image with rasterio\n",
    "#         if file_name.endswith('.tif'):\n",
    "#             with rasterio.open(file_path) as src:\n",
    "#                 image = src.read(1)  # single band raster\n",
    "                \n",
    "#                 # define the min max raster values with rasterio ## I found this is faster than calculating raster statistics with arcpy\n",
    "#                 min = np.min(image)\n",
    "#                 max = np.max(image)\n",
    "                \n",
    "#             # raster calculator, min-max normalize\n",
    "#             normalized = RasterCalculator(\n",
    "#                 rasters = [file_path], \n",
    "#                 input_names = 'x', \n",
    "#                 expression = f'(x - {min}) / ({max} - {min})'\n",
    "#                 )\n",
    "\n",
    "#             # arcpy save raster (cannot overwrite) \n",
    "#             out_path = f'{folder_path}/images_norm/{file_name}'\n",
    "#             normalized.save(out_path)\n",
    "#             print(f'{file_name} normalized and saved at {out_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
