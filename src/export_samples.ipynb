{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import rasterio\n",
    "\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "\n",
    "from arcpy.sa import Raster\n",
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcpy.ia import *\n",
    "arcpy.CheckOutExtension(\"ImageAnalyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This should print the project folder\n",
    "# os.chdir(os.path.dirname(os.getcwd()))\n",
    "# arcpy.env.workspace = os.getcwd()\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define user folder\n",
    "user_folder = <path to user folder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Svalbard & North Sea 2019 (with date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script basically combines different polygons of a same SAR scene to create one single shapefile. This step will be later required for running the create training samples script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# gdf = gpd.read_file(r'C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1ewhh_barents.geojson') # Use EPSG:32636\n",
    "# gdf = gpd.read_file(r'C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1iwvv_ns2019.geojson') # Use EPSG:32631\n",
    "# gdf = gpd.read_file(r'C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1iwvv_rune.geojson') # Use EPSG:32631\n",
    "# gdf = gpd.read_file(r'C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1ewhh_pkf.geojson') # Use EPSG:32632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((31.58613 75.20990, 31.58749 75.20834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((31.82077 75.24779, 31.83398 75.24805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_07_03_145449.tiff</td>\n",
       "      <td>POLYGON ((31.55871 75.20825, 31.57022 75.20004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_07_02_042905.tiff</td>\n",
       "      <td>POLYGON ((31.71543 75.28333, 31.70599 75.28052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_07_02_042905.tiff</td>\n",
       "      <td>POLYGON ((31.93318 75.24572, 31.93250 75.24452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2020_08_27_151138.tiff</td>\n",
       "      <td>POLYGON ((31.70834 75.22585, 31.70614 75.22632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2020_08_27_151138.tiff</td>\n",
       "      <td>POLYGON ((31.55645 75.22683, 31.55448 75.22878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2018_08_27_051729.tiff</td>\n",
       "      <td>POLYGON ((31.84946 75.26372, 31.85241 75.26407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018_08_27_051729.tiff</td>\n",
       "      <td>POLYGON ((31.77864 75.30729, 31.78991 75.30976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2018_08_27_051729.tiff</td>\n",
       "      <td>POLYGON ((31.77439 75.32134, 31.77664 75.32308...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                                           geometry\n",
       "0    2015_08_27_144622.tiff  POLYGON ((31.58613 75.20990, 31.58749 75.20834...\n",
       "1    2015_08_27_144622.tiff  POLYGON ((31.82077 75.24779, 31.83398 75.24805...\n",
       "2    2015_07_03_145449.tiff  POLYGON ((31.55871 75.20825, 31.57022 75.20004...\n",
       "3    2015_07_02_042905.tiff  POLYGON ((31.71543 75.28333, 31.70599 75.28052...\n",
       "4    2015_07_02_042905.tiff  POLYGON ((31.93318 75.24572, 31.93250 75.24452...\n",
       "..                      ...                                                ...\n",
       "278  2020_08_27_151138.tiff  POLYGON ((31.70834 75.22585, 31.70614 75.22632...\n",
       "279  2020_08_27_151138.tiff  POLYGON ((31.55645 75.22683, 31.55448 75.22878...\n",
       "280  2018_08_27_051729.tiff  POLYGON ((31.84946 75.26372, 31.85241 75.26407...\n",
       "281  2018_08_27_051729.tiff  POLYGON ((31.77864 75.30729, 31.78991 75.30976...\n",
       "282  2018_08_27_051729.tiff  POLYGON ((31.77439 75.32134, 31.77664 75.32308...\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This drops columns which are not used later. Reduces data size and avoids raising warnings in the export shapefiles function below\n",
    "gdf.drop(columns={'image_id','Shape_Length','Shape_Area','OBJECTID','OBJECTID_1','OBJECTID_12','layer'},inplace=True,errors='ignore')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((31.58613 75.20990, 31.58749 75.20834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((31.82077 75.24779, 31.83398 75.24805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_07_03_145449.tiff</td>\n",
       "      <td>POLYGON ((31.55871 75.20825, 31.57022 75.20004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_07_13_052621.tiff</td>\n",
       "      <td>POLYGON ((31.55831 75.20775, 31.57788 75.20572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_07_02_042905.tiff</td>\n",
       "      <td>POLYGON ((31.71543 75.28333, 31.70599 75.28052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2020_08_27_151138.tiff</td>\n",
       "      <td>POLYGON ((31.70834 75.22585, 31.70614 75.22632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2020_08_27_151138.tiff</td>\n",
       "      <td>POLYGON ((31.55645 75.22683, 31.55448 75.22878...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018_08_27_051729.tif</td>\n",
       "      <td>POLYGON ((31.84946 75.26372, 31.85241 75.26407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2018_08_27_051729.tif</td>\n",
       "      <td>POLYGON ((31.77864 75.30729, 31.78991 75.30976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2018_08_27_051729.tif</td>\n",
       "      <td>POLYGON ((31.77439 75.32134, 31.77664 75.32308...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                                           geometry\n",
       "0    2015_08_27_144622.tiff  POLYGON ((31.58613 75.20990, 31.58749 75.20834...\n",
       "1    2015_08_27_144622.tiff  POLYGON ((31.82077 75.24779, 31.83398 75.24805...\n",
       "2    2015_07_03_145449.tiff  POLYGON ((31.55871 75.20825, 31.57022 75.20004...\n",
       "3    2015_07_13_052621.tiff  POLYGON ((31.55831 75.20775, 31.57788 75.20572...\n",
       "4    2015_07_02_042905.tiff  POLYGON ((31.71543 75.28333, 31.70599 75.28052...\n",
       "..                      ...                                                ...\n",
       "279  2020_08_27_151138.tiff  POLYGON ((31.70834 75.22585, 31.70614 75.22632...\n",
       "280  2020_08_27_151138.tiff  POLYGON ((31.55645 75.22683, 31.55448 75.22878...\n",
       "281   2018_08_27_051729.tif  POLYGON ((31.84946 75.26372, 31.85241 75.26407...\n",
       "282   2018_08_27_051729.tif  POLYGON ((31.77864 75.30729, 31.78991 75.30976...\n",
       "283   2018_08_27_051729.tif  POLYGON ((31.77439 75.32134, 31.77664 75.32308...\n",
       "\n",
       "[284 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix for rune's format\n",
    "# gdf['date'] = gdf['date'].dt.strftime('%Y_%m_%d_%H%M%S.tiff')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((459714.845 8347506.663, 459749.289 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_08_27_144622.tiff</td>\n",
       "      <td>POLYGON ((466483.552 8351587.914, 466859.381 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_07_03_145449.tiff</td>\n",
       "      <td>POLYGON ((458929.112 8347342.298, 459234.979 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_07_02_042905.tiff</td>\n",
       "      <td>POLYGON ((463575.914 8355614.526, 463301.488 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_07_02_042905.tiff</td>\n",
       "      <td>POLYGON ((469673.971 8351296.503, 469652.296 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date                                           geometry\n",
       "0  2015_08_27_144622.tiff  POLYGON ((459714.845 8347506.663, 459749.289 8...\n",
       "1  2015_08_27_144622.tiff  POLYGON ((466483.552 8351587.914, 466859.381 8...\n",
       "2  2015_07_03_145449.tiff  POLYGON ((458929.112 8347342.298, 459234.979 8...\n",
       "3  2015_07_02_042905.tiff  POLYGON ((463575.914 8355614.526, 463301.488 8...\n",
       "4  2015_07_02_042905.tiff  POLYGON ((469673.971 8351296.503, 469652.296 8..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will reproject the gdf to the right crs depending on the surveyed area\n",
    "# Barents: epsg:32636 ; North_sea: epsg:32631 ; PKF: epsg:32632 ; \n",
    "\n",
    "gdf = gdf.to_crs(epsg=32636)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_grouped_shapefiles(gdf, out_path):\n",
    "    # Ensure the out_path exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    # Group the GeoDataFrame by 'date' column\n",
    "    grouped = gdf.groupby('date')\n",
    "\n",
    "    # Iterate over each group\n",
    "    for date, group in grouped:\n",
    "        # Create a folder for each date\n",
    "        date_folder = os.path.join(out_path, str(date))\n",
    "        os.makedirs(date_folder, exist_ok=True)\n",
    "        \n",
    "        # Define the path to save the shapefile for each group\n",
    "        shapefile_path = os.path.join(date_folder, f\"{date.strip('.tiff')}.shp\")\n",
    "        \n",
    "        # Export the group to the shapefile\n",
    "        group.to_file(shapefile_path)\n",
    "        \n",
    "        print(f\"Shapefile for {date} saved at {shapefile_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Runs the export grouped shapefiles \n",
    "\n",
    "# # shp_folder_path = r\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\"\n",
    "# # shp_folder_path = r\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\"\n",
    "# # shp_folder_path = r\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\"\n",
    "# # shp_folder_path = r\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\"\n",
    "# export_grouped_shapefiles(gdf, shp_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the shapefiles in month subfolders. Not needed per se but helps track script progress and data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through the folders in the directory\n",
    "# for folder_name in os.listdir(shp_folder_path):\n",
    "#     # Construct full path of the folder\n",
    "#     folder_path = os.path.join(shp_folder_path, folder_name)\n",
    "    \n",
    "#     # Ensure it's a folder\n",
    "#     if os.path.isdir(folder_path):\n",
    "#         # Get filenames\n",
    "#         filename = os.path.basename(folder_name)\n",
    "        \n",
    "#         # Extract the month (characters at positions 5 and 6 represent the month) (format: yyyy_mm_dd_HHMMSS.tiff)\n",
    "#         month = filename[5:7] \n",
    "\n",
    "#         # Convert month to an integer to remove leading zeros (e.g., '01' -> 1, '09' -> 9)\n",
    "#         month_int = str(int(month))  # This converts '01' to '1', '02' to '2', etc.\n",
    "\n",
    "#         # Create the new sub-folder based on the month (1 to 12)\n",
    "#         new_folder_path = os.path.join(shp_folder_path, month_int)\n",
    "        \n",
    "#         # Create the sub-folder if it doesn't exist\n",
    "#         if not os.path.exists(new_folder_path):\n",
    "#             os.makedirs(new_folder_path)\n",
    "        \n",
    "#         # Move the folder into the respective sub-folder\n",
    "#         new_folder_path_full = os.path.join(new_folder_path, folder_name)\n",
    "        \n",
    "#         # Move the folder\n",
    "#         shutil.move(folder_path, new_folder_path_full)\n",
    "#         print(f\"Moved {folder_name} to {new_folder_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: lørdag 15. mars 2025 01:49:43<br>Succeeded at lørdag 15. mars 2025 01:49:44 (Elapsed Time: 0,18 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for and disconnect all active connections to a geodatabase\n",
    "arcpy.ClearWorkspaceCache_management()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "zone = 'pkf'\n",
    "gdb_workspace = r\"C:\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\" # replace with path to gdb\n",
    "shp_folder_path = rf\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_{zone}_shp\"\n",
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STRETCH NEW TEST 8bit WITTHOUT COPY RASTER\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "# variable names for temp rasters\n",
    "temp_raster_clipped = 'temp_raster_clipped'\n",
    "temp_raster_8bit = 'temp_raster_8bit'\n",
    "temp_paths = [temp_raster_clipped,temp_raster_8bit]\n",
    "\n",
    "# load each shapefile polygon\n",
    "for tif_name in os.listdir(shp_folder_path):\n",
    "    f_name = tif_name.strip('.tiff')\n",
    "    shp_path = os.path.join(shp_folder_path, f'{tif_name}/{f_name}.shp')\n",
    "    \n",
    "    # create samples for each pixel size (10, 25)\n",
    "    for pixel_size in pixel_sizes:\n",
    "        # check and delete temp rasters if they exist\n",
    "        for p in temp_paths:\n",
    "            if arcpy.Exists(p):\n",
    "                try:\n",
    "                    arcpy.management.Delete(p)\n",
    "                    print(f\"Deleted: {p}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {p}: {e}\")\n",
    "            else:\n",
    "                print(f\"File does not exist: {p}\")\n",
    "\n",
    "        # define input raster path\n",
    "        in_raster_path = rf\"C:\\{user_folder}\\.1\\--Data\\s1\\{zone}_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "        \n",
    "        # check if both samples with (pixel size) already exists. if yes, skip\n",
    "        if not (os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_256_{pixel_size}\\ts_{zone}\\{f_name}') and \n",
    "                os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_{pixel_size}\\ts_{zone}\\{f_name}')):\n",
    "            \n",
    "            # Normalization issue: Clip a bounding box around the slicks\n",
    "            # get the bbox min max coordinates\n",
    "            extent = arcpy.Describe(shp_path).extent\n",
    "\n",
    "            # Extract the coordinates of the bounding box. Add a 5km buffer around\n",
    "            min_x = extent.XMin - buffer\n",
    "            min_y = extent.YMin - buffer\n",
    "            max_x = extent.XMax + buffer\n",
    "            max_y = extent.YMax + buffer\n",
    "            with arcpy.EnvManager(pyramid=\"NONE\"):\n",
    "                arcpy.management.Clip(\n",
    "                    in_raster=in_raster_path,\n",
    "                    rectangle=f\"{min_x} {min_y} {max_x} {max_y}\",\n",
    "                    out_raster=temp_raster_clipped,\n",
    "                    # nodata_value=\"65536\",\n",
    "                    clipping_geometry=\"NONE\",\n",
    "                    maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\"\n",
    "                )\n",
    "            print(f'clipped {tif_name}')\n",
    "\n",
    "            # Apply standard deviation stretch (using 2 standard deviations)\n",
    "            stretched_raster = Stretch(temp_raster_clipped, \"StdDev\", 2)\n",
    "\n",
    "            # # convert raster to 8bit\n",
    "            # arcpy.management.CopyRaster(\n",
    "            #     stretched_raster,     \n",
    "            #     temp_raster_8bit, \n",
    "            #     pixel_type=\"8_BIT_UNSIGNED\" \n",
    "            # )\n",
    "            # print(f'{tif_name} standardized and converted to bit')\n",
    "            \n",
    "        # create samples for each tile size (256, 512)\n",
    "        for tile_size in tile_sizes:\n",
    "            # define parameters for exporting samples\n",
    "            out_path = rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_{zone}\\{f_name}'\n",
    "            stride = tile_size / 2\n",
    "\n",
    "            # create training samples for the tile size and the pixel size\n",
    "            if not os.path.isdir(out_path):\n",
    "                print(f'Creating training samples for {tif_name} ')\n",
    "                ExportTrainingDataForDeepLearning(\n",
    "                    in_raster=stretched_raster, \n",
    "                    out_folder=out_path,\n",
    "                    in_class_data=shp_path,\n",
    "                    image_chip_format='TIFF',\n",
    "                    tile_size_x=f'{tile_size}',\n",
    "                    tile_size_y=f'{tile_size}',\n",
    "                    stride_x=stride,\n",
    "                    stride_y=stride,\n",
    "                    metadata_format='Classified_Tiles',\n",
    "                    buffer_radius=0,\n",
    "                    # rotation_angle=90,\n",
    "                    # min_polygon_overlap_ratio=0.1,\n",
    "                )\n",
    "            print(f'created samples at {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "zone = 'barents'\n",
    "gdb_workspace = r\"C:\\{user_folder}\\Projects\\label_sar\\label_sar.gdb\" # replace with path to gdb\n",
    "shp_folder_path = rf\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_{zone}_shp\"\n",
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## STRETCH NEW TEST 8bit\n",
    "\n",
    "# arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "# # variable names for temp rasters\n",
    "# temp_raster_clipped = 'temp_raster_clipped'\n",
    "# temp_raster_8bit = 'temp_raster_8bit'\n",
    "# temp_paths = [temp_raster_clipped,temp_raster_8bit]\n",
    "\n",
    "# # load each shapefile polygon\n",
    "# for tif_name in os.listdir(shp_folder_path):\n",
    "#     f_name = tif_name.strip('.tiff')\n",
    "#     shp_path = os.path.join(shp_folder_path, f'{tif_name}/{f_name}.shp')\n",
    "    \n",
    "#     # create samples for each pixel size (10, 25)\n",
    "#     for pixel_size in pixel_sizes:\n",
    "#         # check and delete temp rasters if they exist\n",
    "#         for p in temp_paths:\n",
    "#             if arcpy.Exists(p):\n",
    "#                 try:\n",
    "#                     arcpy.management.Delete(p)\n",
    "#                     print(f\"Deleted: {p}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error deleting {p}: {e}\")\n",
    "#             else:\n",
    "#                 print(f\"File does not exist: {p}\")\n",
    "\n",
    "#         # define input raster path\n",
    "#         in_raster_path = rf\"C:\\{user_folder}\\.1\\--Data\\s1\\{zone}_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "        \n",
    "#         # check if both samples with (pixel size) already exists. if yes, skip\n",
    "#         if not (os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_256_{pixel_size}\\ts_{zone}\\{f_name}') and \n",
    "#                 os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_{pixel_size}\\ts_{zone}\\{f_name}')):\n",
    "            \n",
    "#             # Normalization issue: Clip a bounding box around the slicks\n",
    "#             # get the bbox min max coordinates\n",
    "#             extent = arcpy.Describe(shp_path).extent\n",
    "\n",
    "#             # Extract the coordinates of the bounding box. Add a 5km buffer around\n",
    "#             min_x = extent.XMin - buffer\n",
    "#             min_y = extent.YMin - buffer\n",
    "#             max_x = extent.XMax + buffer\n",
    "#             max_y = extent.YMax + buffer\n",
    "\n",
    "#             with arcpy.EnvManager(pyramid=\"NONE\"):\n",
    "#                 arcpy.management.Clip(\n",
    "#                     in_raster=in_raster_path,\n",
    "#                     rectangle=f\"{min_x} {min_y} {max_x} {max_y}\",\n",
    "#                     out_raster=temp_raster_clipped,\n",
    "#                     # nodata_value=\"65536\",\n",
    "#                     clipping_geometry=\"NONE\",\n",
    "#                     maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\"\n",
    "#                 )\n",
    "#             print(f'clipped {tif_name}')\n",
    "\n",
    "#             # Apply standard deviation stretch (using 2 standard deviations)\n",
    "#             stretched_raster = Stretch(temp_raster_clipped, \"StdDev\", 2)\n",
    "\n",
    "#             # # convert raster to 8bit\n",
    "#             # arcpy.management.CopyRaster(\n",
    "#             #     stretched_raster,     \n",
    "#             #     temp_raster_8bit, \n",
    "#             #     pixel_type=\"8_BIT_UNSIGNED\" \n",
    "#             # )\n",
    "#             print(f'{tif_name} standardized and converted to bit')\n",
    "            \n",
    "#         # create samples for each tile size (256, 512)\n",
    "#         for tile_size in tile_sizes:\n",
    "#             # define parameters for exporting samples\n",
    "#             out_path = rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_{zone}\\{f_name}'\n",
    "#             stride = tile_size / 2\n",
    "\n",
    "#             # create training samples for the tile size and the pixel size\n",
    "#             if not os.path.isdir(out_path):\n",
    "#                 print(f'Creating training samples for {tif_name} ')\n",
    "#                 ExportTrainingDataForDeepLearning(\n",
    "#                     in_raster=stretched_raster, \n",
    "#                     out_folder=out_path,\n",
    "#                     in_class_data=shp_path,\n",
    "#                     image_chip_format='TIFF',\n",
    "#                     tile_size_x=f'{tile_size}',\n",
    "#                     tile_size_y=f'{tile_size}',\n",
    "#                     stride_x=stride,\n",
    "#                     stride_y=stride,\n",
    "#                     metadata_format='Classified_Tiles',\n",
    "#                     buffer_radius=0,\n",
    "#                     # rotation_angle=90,\n",
    "#                     # min_polygon_overlap_ratio=0.1,\n",
    "#                 )\n",
    "#             print(f'created samples at {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## North sea 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Params\n",
    "# zone = 'ns2019'\n",
    "# gdb_workspace = r\"C:\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\" # replace with path to gdb\n",
    "# shp_folder_path = rf\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_{zone}_shp\"\n",
    "# tile_sizes = [256,512]\n",
    "# pixel_sizes = [10,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## STRETCH NEW TEST 8bit\n",
    "\n",
    "# arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "# # variable names for temp rasters\n",
    "# temp_raster_clipped = 'temp_raster_clipped'\n",
    "# temp_raster_8bit = 'temp_raster_8bit'\n",
    "# temp_paths = [temp_raster_clipped,temp_raster_8bit]\n",
    "\n",
    "# # load each shapefile polygon\n",
    "# for tif_name in os.listdir(shp_folder_path):\n",
    "#     f_name = tif_name.strip('.tiff')\n",
    "#     shp_path = os.path.join(shp_folder_path, f'{tif_name}/{f_name}.shp')\n",
    "    \n",
    "#     # create samples for each pixel size (10, 25)\n",
    "#     for pixel_size in pixel_sizes:\n",
    "#         # check and delete temp rasters if they exist\n",
    "#         for p in temp_paths:\n",
    "#             if arcpy.Exists(p):\n",
    "#                 try:\n",
    "#                     arcpy.management.Delete(p)\n",
    "#                     print(f\"Deleted: {p}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error deleting {p}: {e}\")\n",
    "#             else:\n",
    "#                 print(f\"File does not exist: {p}\")\n",
    "\n",
    "#         # define input raster path\n",
    "#         in_raster_path = rf\"C:\\{user_folder}\\.1\\--Data\\s1\\{zone}_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "        \n",
    "#         # check if both samples with (pixel size) already exists. if yes, skip\n",
    "#         if not (os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_256_{pixel_size}\\ts_{zone}\\{f_name}') and \n",
    "#                 os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_{pixel_size}\\ts_{zone}\\{f_name}')):\n",
    "            \n",
    "#             # Normalization issue: Clip a bounding box around the slicks\n",
    "#             # get the bbox min max coordinates\n",
    "#             extent = arcpy.Describe(shp_path).extent\n",
    "\n",
    "#             # Extract the coordinates of the bounding box. Add a 5km buffer around\n",
    "#             min_x = extent.XMin - buffer\n",
    "#             min_y = extent.YMin - buffer\n",
    "#             max_x = extent.XMax + buffer\n",
    "#             max_y = extent.YMax + buffer\n",
    "#             with arcpy.EnvManager(pyramid=\"NONE\"):\n",
    "#                 arcpy.management.Clip(\n",
    "#                     in_raster=in_raster_path,\n",
    "#                     rectangle=f\"{min_x} {min_y} {max_x} {max_y}\",\n",
    "#                     out_raster=temp_raster_clipped,\n",
    "#                     # nodata_value=\"65536\",\n",
    "#                     clipping_geometry=\"NONE\",\n",
    "#                     maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\"\n",
    "#                 )\n",
    "#             print(f'clipped {tif_name}')\n",
    "\n",
    "#             # Apply standard deviation stretch (using 2 standard deviations)\n",
    "#             stretched_raster = Stretch(temp_raster_clipped, \"StdDev\", 2)\n",
    "\n",
    "#             # # convert raster to 8bit\n",
    "#             # arcpy.management.CopyRaster(\n",
    "#             #     stretched_raster,     \n",
    "#             #     temp_raster_8bit, \n",
    "#             #     pixel_type=\"8_BIT_UNSIGNED\" \n",
    "#             # )\n",
    "#             # print(f'{tif_name} standardized and converted to bit')\n",
    "            \n",
    "#         # create samples for each tile size (256, 512)\n",
    "#         for tile_size in tile_sizes:\n",
    "#             # define parameters for exporting samples\n",
    "#             out_path = rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_{zone}\\{f_name}'\n",
    "#             stride = tile_size / 2\n",
    "\n",
    "#             # create training samples for the tile size and the pixel size\n",
    "#             if not os.path.isdir(out_path):\n",
    "#                 print(f'Creating training samples for {tif_name} ')\n",
    "#                 ExportTrainingDataForDeepLearning(\n",
    "#                     in_raster=stretched_raster, \n",
    "#                     out_folder=out_path,\n",
    "#                     in_class_data=shp_path,\n",
    "#                     image_chip_format='TIFF',\n",
    "#                     tile_size_x=f'{tile_size}',\n",
    "#                     tile_size_y=f'{tile_size}',\n",
    "#                     stride_x=stride,\n",
    "#                     stride_y=stride,\n",
    "#                     metadata_format='Classified_Tiles',\n",
    "#                     buffer_radius=0,\n",
    "#                     # rotation_angle=90,\n",
    "#                     # min_polygon_overlap_ratio=0.1,\n",
    "#                 )\n",
    "#             print(f'created samples at {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## North sea Rune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "zone = 'rune'\n",
    "gdb_workspace = r\"C:\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\" # replace with path to gdb\n",
    "shp_folder_path = rf\"C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_{zone}_shp\"\n",
    "tile_sizes = [256,512]\n",
    "pixel_sizes = [10,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## STRETCH NEW TEST 8bit\n",
    "\n",
    "# arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "# # variable names for temp rasters\n",
    "# temp_raster_clipped = 'temp_raster_clipped'\n",
    "# temp_raster_8bit = 'temp_raster_8bit'\n",
    "# temp_paths = [temp_raster_clipped,temp_raster_8bit]\n",
    "\n",
    "# # load each shapefile polygon\n",
    "# for tif_name in os.listdir(shp_folder_path):\n",
    "#     f_name = tif_name.strip('.tiff')\n",
    "#     shp_path = os.path.join(shp_folder_path, f'{tif_name}/{f_name}.shp')\n",
    "    \n",
    "#     # create samples for each pixel size (10, 25)\n",
    "#     for pixel_size in pixel_sizes:\n",
    "#         # check and delete temp rasters if they exist\n",
    "#         for p in temp_paths:\n",
    "#             if arcpy.Exists(p):\n",
    "#                 try:\n",
    "#                     arcpy.management.Delete(p)\n",
    "#                     print(f\"Deleted: {p}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error deleting {p}: {e}\")\n",
    "#             else:\n",
    "#                 print(f\"File does not exist: {p}\")\n",
    "\n",
    "#         # define input raster path\n",
    "#         in_raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\{zone}_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "        \n",
    "#         # check if both samples with (pixel size) already exists. if yes, skip\n",
    "#         if not (os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_256_{pixel_size}\\ts_{zone}\\{f_name}') and \n",
    "#                 os.path.isdir(rf'C:\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_{pixel_size}\\ts_{zone}\\{f_name}')):\n",
    "            \n",
    "#             # Normalization issue: Clip a bounding box around the slicks\n",
    "#             # get the bbox min max coordinates\n",
    "#             extent = arcpy.Describe(shp_path).extent\n",
    "\n",
    "#             # Extract the coordinates of the bounding box. Add a 5km buffer around\n",
    "#             min_x = extent.XMin - buffer\n",
    "#             min_y = extent.YMin - buffer\n",
    "#             max_x = extent.XMax + buffer\n",
    "#             max_y = extent.YMax + buffer\n",
    "\n",
    "#             with arcpy.EnvManager(pyramid=\"NONE\"):\n",
    "#                 arcpy.management.Clip(\n",
    "#                     in_raster=in_raster_path,\n",
    "#                     rectangle=f\"{min_x} {min_y} {max_x} {max_y}\",\n",
    "#                     out_raster=temp_raster_clipped,\n",
    "#                     # nodata_value=\"65536\",\n",
    "#                     clipping_geometry=\"NONE\",\n",
    "#                     maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\"\n",
    "#                 )\n",
    "#             print(f'clipped {tif_name}')\n",
    "\n",
    "#             # Apply standard deviation stretch (using 2 standard deviations)\n",
    "#             stretched_raster = Stretch(temp_raster_clipped, \"StdDev\", 2)\n",
    "\n",
    "#             # # convert raster to 8bit\n",
    "#             # arcpy.management.CopyRaster(\n",
    "#             #     stretched_raster,     \n",
    "#             #     temp_raster_8bit, \n",
    "#             #     pixel_type=\"8_BIT_UNSIGNED\" \n",
    "#             # )\n",
    "#             print(f'{tif_name} standardized and converted to bit')\n",
    "            \n",
    "#         # create samples for each tile size (256, 512)\n",
    "#         for tile_size in tile_sizes:\n",
    "#             # define parameters for exporting samples\n",
    "#             out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_{zone}\\{f_name}'\n",
    "#             stride = tile_size / 2\n",
    "\n",
    "#             # create training samples for the tile size and the pixel size\n",
    "#             if not os.path.isdir(out_path):\n",
    "#                 print(f'Creating training samples for {tif_name} ')\n",
    "#                 ExportTrainingDataForDeepLearning(\n",
    "#                     in_raster=stretched_raster, \n",
    "#                     out_folder=out_path,\n",
    "#                     in_class_data=shp_path,\n",
    "#                     image_chip_format='TIFF',\n",
    "#                     tile_size_x=f'{tile_size}',\n",
    "#                     tile_size_y=f'{tile_size}',\n",
    "#                     stride_x=stride,\n",
    "#                     stride_y=stride,\n",
    "#                     metadata_format='Classified_Tiles',\n",
    "#                     buffer_radius=0,\n",
    "#                     # rotation_angle=90,\n",
    "#                     # min_polygon_overlap_ratio=0.1,\n",
    "#                 )\n",
    "#             print(f'created samples at {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "# # variable names for temp rasters\n",
    "# temp_raster_clipped = 'temp_raster_clipped'\n",
    "# temp_raster_8bit = 'temp_raster_8bit'\n",
    "# temp_raster_64bit = 'temp_raster_64bit'\n",
    "# temp_paths = [temp_raster_clipped,temp_raster_8bit, temp_raster_64bit]\n",
    "\n",
    "# # load each shapefile polygon\n",
    "# for tif_name in os.listdir(shp_folder_path): \n",
    "#     f_name = tif_name.strip('.tiff')\n",
    "#     shp_path = os.path.join(shp_folder_path, f'{tif_name}/{f_name}.shp')\n",
    "    \n",
    "#     # create samples for each pixel size (10, 25)\n",
    "#     for pixel_size in pixel_sizes:\n",
    "#         # check and delete temp rasters if they exist\n",
    "#         for p in temp_paths:\n",
    "#             if arcpy.Exists(p):\n",
    "#                 try:\n",
    "#                     arcpy.management.Delete(p)\n",
    "#                     print(f\"Deleted: {p}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error deleting {p}: {e}\")\n",
    "#             else:\n",
    "#                 print(f\"File does not exist: {p}\")\n",
    "\n",
    "#         # define input raster path\n",
    "#         in_raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\{zone}_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "        \n",
    "#         # check if both samples with (pixel size) already exists. if yes, skip\n",
    "#         if not (os.path.isdir(rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_256_{pixel_size}\\ts_{zone}\\{f_name}') and \n",
    "#                 os.path.isdir(rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_512_{pixel_size}\\ts_{zone}\\{f_name}')):\n",
    "            \n",
    "#             # Normalization issue: Clip a bounding box around the slicks\n",
    "#             # get the bbox min max coordinates\n",
    "#             extent = arcpy.Describe(shp_path).extent\n",
    "\n",
    "#             # Extract the coordinates of the bounding box. Add a 5km buffer around\n",
    "#             min_x = extent.XMin - 5000\n",
    "#             min_y = extent.YMin - 5000\n",
    "#             max_x = extent.XMax + 5000\n",
    "#             max_y = extent.YMax + 5000\n",
    "\n",
    "#             with arcpy.EnvManager(pyramid=\"NONE\"):\n",
    "#                 arcpy.management.Clip(\n",
    "#                     in_raster=in_raster_path,\n",
    "#                     rectangle=f\"{min_x} {min_y} {max_x} {max_y}\",\n",
    "#                     out_raster=temp_raster_clipped,\n",
    "#                     # nodata_value=\"65536\",\n",
    "#                     clipping_geometry=\"NONE\",\n",
    "#                     maintain_clipping_extent=\"NO_MAINTAIN_EXTENT\"\n",
    "#                 )\n",
    "#             print(f'clipped raster {temp_raster_clipped}')\n",
    "#             # Get min and max values from the statistics property\n",
    "#             min_val = arcpy.GetRasterProperties_management(temp_raster_clipped, \"MINIMUM\")\n",
    "#             max_val = arcpy.GetRasterProperties_management(temp_raster_clipped, \"MAXIMUM\")\n",
    "\n",
    "#             # min-max normalize 0-255\n",
    "#             normalized = RasterCalculator(\n",
    "#                 rasters = [temp_raster_clipped],\n",
    "#                 input_names = 'x', \n",
    "#                 expression = f'(((x - {min_val}) / ({max_val} - {min_val})) * 255)'\n",
    "#                 )\n",
    "#             # save the temporary raster\n",
    "#             normalized.save(temp_raster_64bit) # cannot overwrite\n",
    "#             print(f'normalized {temp_raster_64bit}')\n",
    "\n",
    "#             # convert raster to 8bit\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 temp_raster_64bit,     \n",
    "#                 temp_raster_8bit, \n",
    "#                 pixel_type=\"8_BIT_UNSIGNED\" \n",
    "#             )\n",
    "\n",
    "#         # create samples for each tile size (256, 512)\n",
    "#         for tile_size in tile_sizes:\n",
    "#             # define parameters for exporting samples\n",
    "#             out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_{zone}\\{f_name}'\n",
    "#             stride = tile_size / 2\n",
    "\n",
    "#             # create training samples for the tile size and the pixel size\n",
    "#             if not os.path.isdir(out_path):\n",
    "#                 print(f'Creating training samples with {temp_raster_8bit} at {out_path} ')\n",
    "#                 ExportTrainingDataForDeepLearning(\n",
    "#                     in_raster=temp_raster_8bit, \n",
    "#                     out_folder=out_path,\n",
    "#                     in_class_data=shp_path,\n",
    "#                     image_chip_format='TIFF',\n",
    "#                     tile_size_x=f'{tile_size}',\n",
    "#                     tile_size_y=f'{tile_size}',\n",
    "#                     stride_x=stride,\n",
    "#                     stride_y=stride,\n",
    "#                     metadata_format='Classified_Tiles',\n",
    "#                     buffer_radius=0,\n",
    "#                     # rotation_angle=90,\n",
    "#                     # min_polygon_overlap_ratio=0.1,\n",
    "#                 )\n",
    "#             print(f'created samples at {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old create samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\pkf_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_pkf\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\barents_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_barents\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rune North Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\rune_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_rune\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### North Sea 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\ns2019_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_ns2019\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 256\n",
    "pixel_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\pkf_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_pkf\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\barents_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_barents\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rune North Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\rune_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_rune\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### North Sea 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\ns2019_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_ns2019\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512 x 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 512\n",
    "pixel_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\pkf_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_pkf\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\barents_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_barents\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rune North Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\rune_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_rune\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### North Sea 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\ns2019_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_ns2019\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 512\n",
    "pixel_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_pkf_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\pkf_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_pkf\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_barents_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\barents_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_barents\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rune North Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_rune_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\rune_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_rune\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### North Sea 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from arcpy import env\n",
    "# # arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "\n",
    "# # Loop through each folder\n",
    "# for folder in os.listdir(r\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\"):\n",
    "#     # Define the path to the shp folders\n",
    "#     month_folder = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1_ns2019_shp\\{folder}\"\n",
    "\n",
    "#     # Find shapefile and tif files paths\n",
    "#     for tif_name in os.listdir(month_folder):\n",
    "#         f_name = tif_name.strip('.tiff')\n",
    "#         shp_path = os.path.join(month_folder, f'{tif_name}/{f_name}.shp')\n",
    "#         # print(shp_path)\n",
    "\n",
    "#         raster_path = rf\"C:\\Users\\{user_folder}\\.1\\--Data\\s1\\ns2019_reproj_{pixel_size}\\{f_name}.tif\"\n",
    "#         temp_8bit_path = r'C:\\Users\\{user_folder}\\OneDrive - University of Bergen\\ArcGIS\\Projects\\label_sar\\label_sar.gdb\\TempRaster'\n",
    "#         out_path = rf'C:\\Users\\{user_folder}\\.1\\--Data\\training_samples\\ts_{tile_size}_{pixel_size}\\ts_ns2019\\{f_name}'\n",
    "#         stride = tile_size / 2\n",
    "#         print(f'Processing: {out_path}')\n",
    "\n",
    "#         try:\n",
    "#         # arcpy.env.workspace = r'OK'\n",
    "#         ##Copy File RasterDataset to GDB Dataset with Background and Nodata setting\n",
    "#             arcpy.management.CopyRaster(\n",
    "#                 in_raster = raster_path,\n",
    "#                 out_rasterdataset = temp_8bit_path,\n",
    "#                 # nodata_value = '0',\n",
    "#                 pixel_type = '8_BIT_UNSIGNED',\n",
    "#                 scale_pixel_value = 'NONE'\n",
    "#                 )\n",
    "#         except:\n",
    "#             print(\"Copy Raster example failed.\")\n",
    "#             print(arcpy.GetMessages())\n",
    "    \n",
    "#         # Execute the ExportTrainingDataForDeepLearning tool\n",
    "#         print('exporting training samples...')\n",
    "#         ExportTrainingDataForDeepLearning(\n",
    "#             in_raster=temp_8bit_path, #temp_raster_path\n",
    "#             out_folder=out_path,\n",
    "#             in_class_data=shp_path,\n",
    "#             image_chip_format='TIFF',\n",
    "#             tile_size_x=f'{tile_size}',\n",
    "#             tile_size_y=f'{tile_size}',\n",
    "#             stride_x=stride,\n",
    "#             stride_y=stride,\n",
    "#             metadata_format='Classified_Tiles',\n",
    "#             buffer_radius=0,\n",
    "#             # rotation_angle=90,\n",
    "#             min_polygon_overlap_ratio=0.15, #5min47 without this #538 with\n",
    "#         )\n",
    "#         # Delete temp 8bit raster\n",
    "#         arcpy.management.Delete(temp_8bit_path)\n",
    "        \n",
    "#     print(f'Processed month {folder}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mamen j'espère que ça a passé\n",
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize training samples (fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# # Function to normalize image pixel values between 0 and 1\n",
    "# def normalize_image(image_data):\n",
    "#     # Normalize to the range [0, 1]\n",
    "#     min_val = np.min(image_data)\n",
    "#     max_val = np.max(image_data)\n",
    "#     return (image_data - min_val) / (max_val - min_val)\n",
    "#  # # Normalize raster values (0-1)\n",
    "#         # # Get the minimum and maximum values of the raster\n",
    "#         # raster_min = arcpy.GetRasterProperties_management(reproj_raster_path, \"MINIMUM\")\n",
    "#         # raster_max = arcpy.GetRasterProperties_management(reproj_raster_path, \"MAXIMUM\")\n",
    "#         # # Ensure float min max values\n",
    "#         # raster_min_value = float(raster_min.getOutput(0))\n",
    "#         # raster_max_value = float(raster_max.getOutput(0))\n",
    "\n",
    "#         # # Normalize equation\n",
    "#         # normalized_raster = (Raster(reproj_raster_path) - raster_min_value) / (raster_max_value - raster_min_value)\n",
    "        \n",
    "# # Path to the root folder containing subfolders\n",
    "# root_folder = r\"C:\\Users\\{user_folder}\\.1\\--Data\\ts_512_10\\ts_rune\"\n",
    "\n",
    "# # Iterate through the subfolders in the root folder\n",
    "# for folder in os.listdir(root_folder):\n",
    "#     folder_path = os.path.join(root_folder, folder)\n",
    "\n",
    "#     # Check if it's a directory (subfolder)\n",
    "#     if os.path.isdir(folder_path):\n",
    "#         images_folder_path = os.path.join(folder_path, 'images')\n",
    "        \n",
    "#         # Check if 'images' subfolder exists\n",
    "#         if os.path.exists(images_folder_path):\n",
    "#             # Iterate through all files in the 'images' subfolder\n",
    "#             for file_name in os.listdir(images_folder_path):\n",
    "#                 file_path = os.path.join(images_folder_path, file_name)\n",
    "\n",
    "#                 # Only process .tif files\n",
    "#                 if file_name.endswith('.tif'):\n",
    "#                     # Open the .tif file using rasterio\n",
    "#                     with rasterio.open(file_path, 'r+') as src:\n",
    "#                         image_data = src.read(1)  # Read the first band (assuming single band, modify if multi-band)\n",
    "                        \n",
    "#                         # Normalize the pixel values\n",
    "#                         normalized_data = normalize_image(image_data)\n",
    "\n",
    "#                         # Overwrite the existing .tif file with normalized data\n",
    "#                         src.write(normalized_data, 1)  # Write the normalized data to the first band\n",
    "#                         print(f\"Normalized and overwritten: {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count images and slicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "1138\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r'C:\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1iwvv_ns2019.geojson')\n",
    "gdf.drop(columns={'Shape_Length','Shape_Area','OBJECTID'},inplace=True,errors='ignore')\n",
    "print(gdf['date'].nunique())\n",
    "print(len(gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "585\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r'C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1iwvv_rune.geojson')\n",
    "gdf.drop(columns={'Shape_Length','Shape_Area','OBJECTID'},inplace=True,errors='ignore')\n",
    "print(gdf['date'].nunique())\n",
    "print(len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r'C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1ewhh_pkf.geojson')\n",
    "gdf.drop(columns={'Shape_Length','Shape_Area','OBJECTID'},inplace=True,errors='ignore')\n",
    "print(gdf['date'].nunique())\n",
    "print(len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r'C:\\Users\\{user_folder}\\.1\\--Data\\labeled_slick_polygons\\s1ewhh_barents.geojson')\n",
    "gdf.drop(columns={'Shape_Length','Shape_Area','OBJECTID'},inplace=True,errors='ignore')\n",
    "print(gdf['date'].nunique())\n",
    "print(len(gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019_01_02_170907.tiff</td>\n",
       "      <td>POLYGON ((7.50694 57.18104, 7.52037 57.1787, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019_01_02_170907.tiff</td>\n",
       "      <td>POLYGON ((7.58443 57.21511, 7.58871 57.21336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019_01_02_170932.tiff</td>\n",
       "      <td>POLYGON ((9.4657 58.66601, 9.47829 58.68432, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019_01_03_054830.tiff</td>\n",
       "      <td>POLYGON ((8.44138 57.6134, 8.45048 57.60593, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019_01_04_174234.tiff</td>\n",
       "      <td>POLYGON ((-0.98725 55.47355, -0.98741 55.47483...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>2019_12_26_172634.tiff</td>\n",
       "      <td>POLYGON ((4.19972 60.28455, 4.20058 60.28289, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>2019_12_26_172634.tiff</td>\n",
       "      <td>POLYGON ((4.22338 60.27563, 4.22074 60.27378, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>2019_12_27_060431.tiff</td>\n",
       "      <td>POLYGON ((3.03916 60.48378, 3.03769 60.48968, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>2019_12_31_062031.tiff</td>\n",
       "      <td>POLYGON ((-0.14275 58.89698, -0.14235 58.89899...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>2019_12_31_173343.tiff</td>\n",
       "      <td>POLYGON ((2.45107 55.57889, 2.43551 55.57962, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "0     2019_01_02_170907.tiff   \n",
       "1     2019_01_02_170907.tiff   \n",
       "2     2019_01_02_170932.tiff   \n",
       "3     2019_01_03_054830.tiff   \n",
       "4     2019_01_04_174234.tiff   \n",
       "...                      ...   \n",
       "1133  2019_12_26_172634.tiff   \n",
       "1134  2019_12_26_172634.tiff   \n",
       "1135  2019_12_27_060431.tiff   \n",
       "1136  2019_12_31_062031.tiff   \n",
       "1137  2019_12_31_173343.tiff   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((7.50694 57.18104, 7.52037 57.1787, 7...  \n",
       "1     POLYGON ((7.58443 57.21511, 7.58871 57.21336, ...  \n",
       "2     POLYGON ((9.4657 58.66601, 9.47829 58.68432, 9...  \n",
       "3     POLYGON ((8.44138 57.6134, 8.45048 57.60593, 8...  \n",
       "4     POLYGON ((-0.98725 55.47355, -0.98741 55.47483...  \n",
       "...                                                 ...  \n",
       "1133  POLYGON ((4.19972 60.28455, 4.20058 60.28289, ...  \n",
       "1134  POLYGON ((4.22338 60.27563, 4.22074 60.27378, ...  \n",
       "1135  POLYGON ((3.03916 60.48378, 3.03769 60.48968, ...  \n",
       "1136  POLYGON ((-0.14275 58.89698, -0.14235 58.89899...  \n",
       "1137  POLYGON ((2.45107 55.57889, 2.43551 55.57962, ...  \n",
       "\n",
       "[1138 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "06    331\n",
       "05    239\n",
       "07    169\n",
       "08    129\n",
       "09     68\n",
       "04     45\n",
       "03     40\n",
       "10     29\n",
       "11     29\n",
       "02     25\n",
       "01     17\n",
       "12     17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf['month'] = gdf['date'].str[5:7]\n",
    "gdf['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename test/train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_1',\n",
       " 'sample_10',\n",
       " 'sample_100',\n",
       " 'sample_101',\n",
       " 'sample_102',\n",
       " 'sample_103',\n",
       " 'sample_104',\n",
       " 'sample_105',\n",
       " 'sample_106',\n",
       " 'sample_107',\n",
       " 'sample_108',\n",
       " 'sample_109',\n",
       " 'sample_11',\n",
       " 'sample_110',\n",
       " 'sample_111',\n",
       " 'sample_112',\n",
       " 'sample_113',\n",
       " 'sample_114',\n",
       " 'sample_115',\n",
       " 'sample_116',\n",
       " 'sample_117',\n",
       " 'sample_118',\n",
       " 'sample_119',\n",
       " 'sample_12',\n",
       " 'sample_120',\n",
       " 'sample_121',\n",
       " 'sample_122',\n",
       " 'sample_123',\n",
       " 'sample_124',\n",
       " 'sample_125',\n",
       " 'sample_126',\n",
       " 'sample_127',\n",
       " 'sample_128',\n",
       " 'sample_129',\n",
       " 'sample_13',\n",
       " 'sample_130',\n",
       " 'sample_131',\n",
       " 'sample_132',\n",
       " 'sample_133',\n",
       " 'sample_134',\n",
       " 'sample_135',\n",
       " 'sample_136',\n",
       " 'sample_137',\n",
       " 'sample_138',\n",
       " 'sample_139',\n",
       " 'sample_14',\n",
       " 'sample_140',\n",
       " 'sample_141',\n",
       " 'sample_142',\n",
       " 'sample_143',\n",
       " 'sample_144',\n",
       " 'sample_145',\n",
       " 'sample_146',\n",
       " 'sample_147',\n",
       " 'sample_148',\n",
       " 'sample_149',\n",
       " 'sample_15',\n",
       " 'sample_150',\n",
       " 'sample_151',\n",
       " 'sample_152',\n",
       " 'sample_153',\n",
       " 'sample_154',\n",
       " 'sample_155',\n",
       " 'sample_156',\n",
       " 'sample_157',\n",
       " 'sample_158',\n",
       " 'sample_16',\n",
       " 'sample_17',\n",
       " 'sample_18',\n",
       " 'sample_19',\n",
       " 'sample_2',\n",
       " 'sample_20',\n",
       " 'sample_21',\n",
       " 'sample_22',\n",
       " 'sample_23',\n",
       " 'sample_24',\n",
       " 'sample_25',\n",
       " 'sample_26',\n",
       " 'sample_27',\n",
       " 'sample_28',\n",
       " 'sample_29',\n",
       " 'sample_3',\n",
       " 'sample_30',\n",
       " 'sample_31',\n",
       " 'sample_32',\n",
       " 'sample_33',\n",
       " 'sample_34',\n",
       " 'sample_35',\n",
       " 'sample_36',\n",
       " 'sample_37',\n",
       " 'sample_38',\n",
       " 'sample_39',\n",
       " 'sample_4',\n",
       " 'sample_40',\n",
       " 'sample_41',\n",
       " 'sample_42',\n",
       " 'sample_43',\n",
       " 'sample_44',\n",
       " 'sample_45',\n",
       " 'sample_46',\n",
       " 'sample_47',\n",
       " 'sample_48',\n",
       " 'sample_49',\n",
       " 'sample_5',\n",
       " 'sample_50',\n",
       " 'sample_51',\n",
       " 'sample_52',\n",
       " 'sample_53',\n",
       " 'sample_54',\n",
       " 'sample_55',\n",
       " 'sample_56',\n",
       " 'sample_57',\n",
       " 'sample_58',\n",
       " 'sample_59',\n",
       " 'sample_6',\n",
       " 'sample_60',\n",
       " 'sample_61',\n",
       " 'sample_62',\n",
       " 'sample_63',\n",
       " 'sample_64',\n",
       " 'sample_65',\n",
       " 'sample_66',\n",
       " 'sample_67',\n",
       " 'sample_68',\n",
       " 'sample_69',\n",
       " 'sample_7',\n",
       " 'sample_70',\n",
       " 'sample_71',\n",
       " 'sample_72',\n",
       " 'sample_73',\n",
       " 'sample_74',\n",
       " 'sample_75',\n",
       " 'sample_76',\n",
       " 'sample_77',\n",
       " 'sample_78',\n",
       " 'sample_79',\n",
       " 'sample_8',\n",
       " 'sample_80',\n",
       " 'sample_81',\n",
       " 'sample_82',\n",
       " 'sample_83',\n",
       " 'sample_84',\n",
       " 'sample_85',\n",
       " 'sample_86',\n",
       " 'sample_87',\n",
       " 'sample_88',\n",
       " 'sample_89',\n",
       " 'sample_9',\n",
       " 'sample_90',\n",
       " 'sample_91',\n",
       " 'sample_92',\n",
       " 'sample_93',\n",
       " 'sample_94',\n",
       " 'sample_95',\n",
       " 'sample_96',\n",
       " 'sample_97',\n",
       " 'sample_98',\n",
       " 'sample_99']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to training samples folder\n",
    "ts_folder = 'data/training_samples/ts_256_25/ts_svalbard - Copy'\n",
    "\n",
    "# List all the folders in the ts folder\n",
    "folders = [f for f in os.listdir(ts_folder) if os.path.isdir(os.path.join(ts_folder, f))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'sample_1' to 'image_35'\n",
      "Renamed 'sample_10' to 'image_146'\n",
      "Renamed 'sample_100' to 'image_17'\n",
      "Renamed 'sample_101' to 'image_66'\n",
      "Renamed 'sample_102' to 'image_31'\n",
      "Renamed 'sample_103' to 'image_127'\n",
      "Renamed 'sample_104' to 'image_116'\n",
      "Renamed 'sample_105' to 'image_121'\n",
      "Renamed 'sample_106' to 'image_98'\n",
      "Renamed 'sample_107' to 'image_54'\n",
      "Renamed 'sample_108' to 'image_25'\n",
      "Renamed 'sample_109' to 'image_125'\n",
      "Renamed 'sample_11' to 'image_8'\n",
      "Renamed 'sample_110' to 'image_100'\n",
      "Renamed 'sample_111' to 'image_111'\n",
      "Renamed 'sample_112' to 'image_1'\n",
      "Renamed 'sample_113' to 'image_115'\n",
      "Renamed 'sample_114' to 'image_69'\n",
      "Renamed 'sample_115' to 'image_59'\n",
      "Renamed 'sample_116' to 'image_27'\n",
      "Renamed 'sample_117' to 'image_82'\n",
      "Renamed 'sample_118' to 'image_157'\n",
      "Renamed 'sample_119' to 'image_6'\n",
      "Renamed 'sample_12' to 'image_7'\n",
      "Renamed 'sample_120' to 'image_3'\n",
      "Renamed 'sample_121' to 'image_150'\n",
      "Renamed 'sample_122' to 'image_56'\n",
      "Renamed 'sample_123' to 'image_109'\n",
      "Renamed 'sample_124' to 'image_137'\n",
      "Renamed 'sample_125' to 'image_57'\n",
      "Renamed 'sample_126' to 'image_113'\n",
      "Renamed 'sample_127' to 'image_151'\n",
      "Renamed 'sample_128' to 'image_64'\n",
      "Renamed 'sample_129' to 'image_71'\n",
      "Renamed 'sample_13' to 'image_30'\n",
      "Renamed 'sample_130' to 'image_45'\n",
      "Renamed 'sample_131' to 'image_124'\n",
      "Renamed 'sample_132' to 'image_87'\n",
      "Renamed 'sample_133' to 'image_29'\n",
      "Renamed 'sample_134' to 'image_133'\n",
      "Renamed 'sample_135' to 'image_140'\n",
      "Renamed 'sample_136' to 'image_38'\n",
      "Renamed 'sample_137' to 'image_134'\n",
      "Renamed 'sample_138' to 'image_149'\n",
      "Renamed 'sample_139' to 'image_108'\n",
      "Renamed 'sample_14' to 'image_72'\n",
      "Renamed 'sample_140' to 'image_83'\n",
      "Renamed 'sample_141' to 'image_13'\n",
      "Renamed 'sample_142' to 'image_24'\n",
      "Renamed 'sample_143' to 'image_81'\n",
      "Renamed 'sample_144' to 'image_93'\n",
      "Renamed 'sample_145' to 'image_117'\n",
      "Renamed 'sample_146' to 'image_16'\n",
      "Renamed 'sample_147' to 'image_96'\n",
      "Renamed 'sample_148' to 'image_43'\n",
      "Renamed 'sample_149' to 'image_114'\n",
      "Renamed 'sample_15' to 'image_92'\n",
      "Renamed 'sample_150' to 'image_65'\n",
      "Renamed 'sample_151' to 'image_55'\n",
      "Renamed 'sample_152' to 'image_101'\n",
      "Renamed 'sample_153' to 'image_86'\n",
      "Renamed 'sample_154' to 'image_148'\n",
      "Renamed 'sample_155' to 'image_39'\n",
      "Renamed 'sample_156' to 'image_37'\n",
      "Renamed 'sample_157' to 'image_76'\n",
      "Renamed 'sample_158' to 'image_126'\n",
      "Renamed 'sample_16' to 'image_99'\n",
      "Renamed 'sample_17' to 'image_51'\n",
      "Renamed 'sample_18' to 'image_94'\n",
      "Renamed 'sample_19' to 'image_5'\n",
      "Renamed 'sample_2' to 'image_62'\n",
      "Renamed 'sample_20' to 'image_32'\n",
      "Renamed 'sample_21' to 'image_52'\n",
      "Renamed 'sample_22' to 'image_142'\n",
      "Renamed 'sample_23' to 'image_23'\n",
      "Renamed 'sample_24' to 'image_47'\n",
      "Renamed 'sample_25' to 'image_147'\n",
      "Renamed 'sample_26' to 'image_48'\n",
      "Renamed 'sample_27' to 'image_12'\n",
      "Renamed 'sample_28' to 'image_129'\n",
      "Renamed 'sample_29' to 'image_155'\n",
      "Renamed 'sample_3' to 'image_14'\n",
      "Renamed 'sample_30' to 'image_21'\n",
      "Renamed 'sample_31' to 'image_67'\n",
      "Renamed 'sample_32' to 'image_91'\n",
      "Renamed 'sample_33' to 'image_131'\n",
      "Renamed 'sample_34' to 'image_63'\n",
      "Renamed 'sample_35' to 'image_4'\n",
      "Renamed 'sample_36' to 'image_61'\n",
      "Renamed 'sample_37' to 'image_136'\n",
      "Renamed 'sample_38' to 'image_40'\n",
      "Renamed 'sample_39' to 'image_74'\n",
      "Renamed 'sample_4' to 'image_22'\n",
      "Renamed 'sample_40' to 'image_78'\n",
      "Renamed 'sample_41' to 'image_122'\n",
      "Renamed 'sample_42' to 'image_128'\n",
      "Renamed 'sample_43' to 'image_143'\n",
      "Renamed 'sample_44' to 'image_50'\n",
      "Renamed 'sample_45' to 'image_144'\n",
      "Renamed 'sample_46' to 'image_158'\n",
      "Renamed 'sample_47' to 'image_132'\n",
      "Renamed 'sample_48' to 'image_36'\n",
      "Renamed 'sample_49' to 'image_15'\n",
      "Renamed 'sample_5' to 'image_26'\n",
      "Renamed 'sample_50' to 'image_33'\n",
      "Renamed 'sample_51' to 'image_84'\n",
      "Renamed 'sample_52' to 'image_95'\n",
      "Renamed 'sample_53' to 'image_53'\n",
      "Renamed 'sample_54' to 'image_103'\n",
      "Renamed 'sample_55' to 'image_18'\n",
      "Renamed 'sample_56' to 'image_104'\n",
      "Renamed 'sample_57' to 'image_79'\n",
      "Renamed 'sample_58' to 'image_105'\n",
      "Renamed 'sample_59' to 'image_88'\n",
      "Renamed 'sample_6' to 'image_97'\n",
      "Renamed 'sample_60' to 'image_85'\n",
      "Renamed 'sample_61' to 'image_9'\n",
      "Renamed 'sample_62' to 'image_34'\n",
      "Renamed 'sample_63' to 'image_112'\n",
      "Renamed 'sample_64' to 'image_77'\n",
      "Renamed 'sample_65' to 'image_28'\n",
      "Renamed 'sample_66' to 'image_138'\n",
      "Renamed 'sample_67' to 'image_154'\n",
      "Renamed 'sample_68' to 'image_110'\n",
      "Renamed 'sample_69' to 'image_60'\n",
      "Renamed 'sample_7' to 'image_73'\n",
      "Renamed 'sample_70' to 'image_139'\n",
      "Renamed 'sample_71' to 'image_106'\n",
      "Renamed 'sample_72' to 'image_153'\n",
      "Renamed 'sample_73' to 'image_80'\n",
      "Renamed 'sample_74' to 'image_46'\n",
      "Renamed 'sample_75' to 'image_120'\n",
      "Renamed 'sample_76' to 'image_123'\n",
      "Renamed 'sample_77' to 'image_49'\n",
      "Renamed 'sample_78' to 'image_44'\n",
      "Renamed 'sample_79' to 'image_20'\n",
      "Renamed 'sample_8' to 'image_75'\n",
      "Renamed 'sample_80' to 'image_11'\n",
      "Renamed 'sample_81' to 'image_58'\n",
      "Renamed 'sample_82' to 'image_145'\n",
      "Renamed 'sample_83' to 'image_130'\n",
      "Renamed 'sample_84' to 'image_141'\n",
      "Renamed 'sample_85' to 'image_156'\n",
      "Renamed 'sample_86' to 'image_107'\n",
      "Renamed 'sample_87' to 'image_2'\n",
      "Renamed 'sample_88' to 'image_41'\n",
      "Renamed 'sample_89' to 'image_42'\n",
      "Renamed 'sample_9' to 'image_89'\n",
      "Renamed 'sample_90' to 'image_19'\n",
      "Renamed 'sample_91' to 'image_102'\n",
      "Renamed 'sample_92' to 'image_70'\n",
      "Renamed 'sample_93' to 'image_135'\n",
      "Renamed 'sample_94' to 'image_10'\n",
      "Renamed 'sample_95' to 'image_119'\n",
      "Renamed 'sample_96' to 'image_68'\n",
      "Renamed 'sample_97' to 'image_118'\n",
      "Renamed 'sample_98' to 'image_90'\n",
      "Renamed 'sample_99' to 'image_152'\n"
     ]
    }
   ],
   "source": [
    "# Path to training samples folder\n",
    "ts_folder = 'data/training_samples/ts_256_25/ts_svalbard - Copy'\n",
    "\n",
    "# List all the folders in the ts folder\n",
    "folders = [f for f in os.listdir(ts_folder) if os.path.isdir(os.path.join(ts_folder, f))]\n",
    "\n",
    "random.seed(1)\n",
    "rand_ints = random.sample(range(1, 159), 158)\n",
    "\n",
    "# Rename each folder \n",
    "i = 0\n",
    "for folder in os.listdir(ts_folder):\n",
    "    old_folder_path = os.path.join(ts_folder, folder)\n",
    "    new_folder_name = f\"image_{rand_ints[i]}\"\n",
    "    new_folder_path = os.path.join(ts_folder, new_folder_name)\n",
    "    i += 1\n",
    "    # Rename the folder\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    print(f\"Renamed '{folder}' to '{new_folder_name}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
